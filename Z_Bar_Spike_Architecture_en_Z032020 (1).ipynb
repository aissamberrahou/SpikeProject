{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Z_Bar Spike Architecture en Z032020.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QWWWdJizhdjf",
        "mG7MUl37hQzt",
        "TYf7a4pZxK4G",
        "VdzVZe3-cId4",
        "tsCZGxDHjmWA",
        "yVT2yA3ExK4f",
        "sIGwELbZgU4g",
        "oMzZYiHgrSAM"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WipMUANapwQH"
      },
      "source": [
        "# Installation nengo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INdmddVTxKzd",
        "outputId": "c7f91859-9939-4321-89b0-c186f55953ef"
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install nengo\n",
        "!pip install nengo_dl\n",
        "#!pip install nengo_ocl\n",
        "!pip install urllib3\n",
        "!pip install nengo-extras\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import nengo\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#import nengo_dl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nengo\n",
            "  Downloading nengo-3.1.0-py3-none-any.whl (523 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 523 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from nengo) (1.19.5)\n",
            "Installing collected packages: nengo\n",
            "Successfully installed nengo-3.1.0\n",
            "Collecting nengo_dl\n",
            "  Downloading nengo-dl-3.4.2.tar.gz (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 5.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from nengo_dl) (2.11.3)\n",
            "Collecting progressbar2>=3.39.0\n",
            "  Downloading progressbar2-3.53.3-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: nengo>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from nengo_dl) (3.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from nengo_dl) (21.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from nengo_dl) (1.19.5)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from nengo_dl) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10.1->nengo_dl) (2.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->nengo_dl) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from progressbar2>=3.39.0->nengo_dl) (1.15.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2>=3.39.0->nengo_dl) (2.5.6)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (2.6.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (2.6.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (2.6.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (3.17.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (1.40.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (0.37.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->nengo_dl) (0.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.2.0->nengo_dl) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2.0->nengo_dl) (3.5.0)\n",
            "Building wheels for collected packages: nengo-dl\n",
            "  Building wheel for nengo-dl (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nengo-dl: filename=nengo_dl-3.4.2-py3-none-any.whl size=204641 sha256=e852a5bcf952a50c138ee96d6650c748739b1e55ca9e7ce45cc0bf943ae2580b\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/22/9b/abf4313c8943df36addfec2336d2d6559c9f7a85f7bf0c67b2\n",
            "Successfully built nengo-dl\n",
            "Installing collected packages: progressbar2, nengo-dl\n",
            "  Attempting uninstall: progressbar2\n",
            "    Found existing installation: progressbar2 3.38.0\n",
            "    Uninstalling progressbar2-3.38.0:\n",
            "      Successfully uninstalled progressbar2-3.38.0\n",
            "Successfully installed nengo-dl-3.4.2 progressbar2-3.53.3\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (1.24.3)\n",
            "Collecting nengo-extras\n",
            "  Downloading nengo_extras-0.4.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=1.4 in /usr/local/lib/python3.7/dist-packages (from nengo-extras) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from nengo-extras) (1.19.5)\n",
            "Requirement already satisfied: nengo in /usr/local/lib/python3.7/dist-packages (from nengo-extras) (3.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4->nengo-extras) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4->nengo-extras) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4->nengo-extras) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4->nengo-extras) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4->nengo-extras) (1.15.0)\n",
            "Installing collected packages: nengo-extras\n",
            "Successfully installed nengo-extras-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqncCHSZxKz6"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "\n",
        "import nengo\n",
        "#import nengo_ocl\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import (Activation, Conv2D, Dense, Dropout, Flatten,AvgPool2D,MaxPooling2D,LeakyReLU,Input,Concatenate,Subtract)\n",
        "from tensorflow.python.keras.layers.noise import GaussianNoise\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "#from nengo_extras.keras import (load_model_pair, save_model_pair, SequentialNetwork, SoftLIF)\n",
        "from nengo_extras.gui import image_display_function"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWWWdJizhdjf"
      },
      "source": [
        "# **Load MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QAxc6OBxK1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abbd624-76e5-4b7b-c829-ec9a0946d243"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import (Activation, Conv2D,GlobalAveragePooling2D, Dense, Dropout, Flatten,AvgPool2D,MaxPooling2D,LeakyReLU,Input,Concatenate,Subtract)\n",
        "from tensorflow.python.keras.layers.noise import GaussianNoise\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "# --- Parameters\n",
        "np.random.seed(1)\n",
        "filename = 'mnist_spiking_cnn'\n",
        "run_in_theano = False\n",
        "#use_ocl = True\n",
        "presentation_time = 0.15\n",
        "n_presentations = 100\n",
        "\n",
        "# --- Load data\n",
        "img_rows, img_cols = 28, 28\n",
        "n_classes = 10\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = (mnist.load_data())\n",
        "data_format = 'channels_last'\n",
        "\n",
        "\n",
        "def preprocess(X):\n",
        "    X = X.astype('float32') / 255\n",
        "    if data_format == 'channels_first':\n",
        "        X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    else:\n",
        "        X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "X_train, X_test = preprocess(X_train), preprocess(X_test)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG7MUl37hQzt"
      },
      "source": [
        "# **# Hahn moments**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hw3mMF_xK14",
        "outputId": "7217396f-2df4-4b15-e5d3-04d1f5832a9a"
      },
      "source": [
        "from __future__ import division\n",
        "from numpy import *\n",
        "import math\n",
        "import matplotlib.pylab as pt\n",
        "import mpmath\n",
        "from decimal import Decimal, localcontext\n",
        "\n",
        "def KernelsHahn(x, n, alpha, beta, N):\n",
        "\n",
        "    return mpmath.hyp3f2(-n, n + alpha + beta + 1, -x, alpha + 1, -N, 1,accurate_small=False)\n",
        "\n",
        "def HahnPolynome(n, N, alpha, beta):\n",
        "    with localcontext() as ctx:\n",
        "        ctx.prec =10\n",
        "        n=n+1\n",
        "        gh=zeros(n)\n",
        "        om=zeros(N)\n",
        "        A=zeros((n,N))\n",
        "        for i in range (0,n):\n",
        "\n",
        "            gh[i]=Decimal(ghoHahn(i,alpha, beta, N))\n",
        "\n",
        "        for j in range(0,N):\n",
        "            om[j]=Decimal(omegaHahn(j, alpha, beta, N))\n",
        "\n",
        "\n",
        "        for i in range(0,n):\n",
        "            #print(i)\n",
        "            for j in range(0,N):\n",
        "                #print('omega',om[j],' gho:', gh[i])\n",
        "                aa=Decimal(abs((om[j])/(gh[i])))\n",
        "                #print(aa)\n",
        "                A[i, j] = KernelsHahn(j, i, alpha, beta, N) * float(aa.sqrt())\n",
        "\n",
        "        #pt.plot(transpose(A[i,:]), label='n='+str(i))\n",
        "\n",
        "\n",
        "\n",
        "    #A=transpose(A)\n",
        "\n",
        "        #pt.plot(transpose(A))\n",
        "\n",
        "    #pt.legend()\n",
        "        #pt.show()\n",
        "    return A\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def omegaHahn(x, alpha, beta, N):\n",
        "    with localcontext() as ctx:\n",
        "        ctx.prec = 100  # 100 digits precision\n",
        "        a=Decimal(0)\n",
        "        b=Decimal(0)\n",
        "        c=Decimal(0)\n",
        "        param1 = (alpha + 1)\n",
        "        param2 = (x)\n",
        "        param3 = (beta + 1)\n",
        "        param4 = (N - x)\n",
        "        a =Decimal(pochHamer(param1, param2) * pochHamer(param3, param4))\n",
        "        b =Decimal(math.factorial(N - x) * math.factorial(x))\n",
        "\n",
        "        c = Decimal(Decimal(a / b) / Decimal(1E+308))\n",
        "        #print('omega:',c )\n",
        "    #return c.ln()\n",
        "    return c\n",
        "    #print(a, '  ', b, '  ', c)\n",
        "\n",
        "\n",
        "\n",
        "def pochHamer(a, k):\n",
        "\n",
        "    if (k == 0):\n",
        "        akk = 1\n",
        "    elif k == 1:\n",
        "        akk = a\n",
        "    else:\n",
        "        akk = a\n",
        "    for i in range(1,k):\n",
        "        akk = akk * (a + i)\n",
        "\n",
        "    return akk\n",
        "\n",
        "def ghoHahn(n, alpha, beta, N):\n",
        "    with localcontext() as ctx:\n",
        "        ctx.prec = 100  # 100 digits precision\n",
        "        \n",
        "        param1 = Decimal(n + alpha + beta + 1);\n",
        "        param2 = (N + 1);\n",
        "        param3 = Decimal(alpha + 1);\n",
        "        param4 = Decimal(-N);\n",
        "        param5=Decimal(pow((-1), n))\n",
        "        #print(Decimal(math.factorial(n)))\n",
        "        a = (Decimal(param5 * pochHamer(param1, param2) * pochHamer((beta + 1), n) * Decimal(math.factorial(n))))\n",
        "        \n",
        "        b = (Decimal(((2 * n) + alpha + beta + 1) * pochHamer(param3, n) * pochHamer(param4, n) *Decimal( math.factorial(N))))\n",
        "\n",
        "        c = Decimal(Decimal(a / b) / Decimal(1E+308))\n",
        "        #print('gho:', c)\n",
        "\n",
        "    #return c.ln()\n",
        "    return c\n",
        "\n",
        "\n",
        "\n",
        "def ImageReconstructionHahn3DV2(Mt, ordre, a1, b1, a2, b2, a3, b3):\n",
        "    M,N,L=shape(Mt)\n",
        "    A=HahnPolynome(ordre, M, a1, b1)\n",
        "    B = A\n",
        "    ImageRec=zeros((M,M,M),uint8)\n",
        "    for i in range(0,L):\n",
        "        img2D=Mt[:,:, i]\n",
        "        MMM = matmul(A , img2D)\n",
        "        MMM = matmul(MMM, transpose(B));\n",
        "        ImageRec[:,:, i] = matmul(matmul(transpose(A),MMM),B)\n",
        "    return ImageRec\n",
        "\n",
        "def ImageReconstructionHahn3D(Mt, ordre, a1, b1, a2, b2,a3, b3):\n",
        "    MM, NN, LL = shape(Mt)\n",
        "    print(MM, NN, LL)\n",
        "    K111=HahnPolynome(ordre,LL , a1, b1)\n",
        "    K222=K111\n",
        "    K333=K111\n",
        "    #K222 = HahnPolynome(ordre, n, a2, b2)\n",
        "    #K333=HahnPolynome(ordre, n, a3, b3)\n",
        "    ordre=ordre+1\n",
        "    MMM=zeros([ordre,ordre,LL])\n",
        "\n",
        "    for i in range(0,LL):\n",
        "        MMM[:,:, i]=matmul(K111, matmul(Mt[:,:, i],transpose(K222)))\n",
        "\n",
        "    MMMM = zeros((LL,ordre, ordre))\n",
        "    for i in range(0,ordre):\n",
        "        for j in range(0,ordre):\n",
        "            for k in range(0,LL):\n",
        "                MMMM[k, j , i] = MMM[i , j , k]\n",
        "\n",
        "    momentD = zeros((ordre, ordre, ordre))\n",
        "    for z in range(0,ordre):\n",
        "        momentD[:,:, z]=(matmul(K333,MMMM[:,:, z ]))\n",
        "\n",
        "    MMRec1 = zeros((LL, LL, ordre))\n",
        "    for i in range(0,ordre):\n",
        "        MMRec1[:,:, i ]=(matmul(transpose(K111),matmul(momentD[:,:,i],K222)))\n",
        "\n",
        "    MMRec11 = zeros((ordre,LL, LL))\n",
        "    for i in range(0,LL):\n",
        "        for j in range(0,LL):\n",
        "            for k in range(0,ordre):\n",
        "                MMRec11[k, j, i] = MMRec1[i, j, k ]\n",
        "\n",
        "    MMRec4 = zeros((LL, LL, LL))\n",
        "    for zz in range(0,LL):\n",
        "        MMRec4[:,:, zz]=(matmul(transpose(K333),MMRec11[:,:,zz]))\n",
        "\n",
        "    return (MMRec4)\n",
        "\n",
        "\n",
        "\n",
        "def  aCoef(n, a, b, N):\n",
        "\n",
        "    if n == 0:\n",
        "\n",
        "        a1 = 1\n",
        "        a2 = 0\n",
        "        a3 = 0\n",
        "        a4 = 0\n",
        "\n",
        "    elif n == 1:\n",
        "        a1 = 1\n",
        "        a2 = -(n * (n + a + b + 1)) / (N * (a + 1));\n",
        "        a3 = 0\n",
        "        a4 = 0\n",
        "    else:# n == 2:\n",
        "        a1 = 1\n",
        "        b = -(n * (n + a + b + 1)) / (N * (a + 1));\n",
        "        c = (pow(n,2) - n) * (pow(n + a + b + 1, 2) + (n + a + b + 1)) / (2 * (pow((a + 1), 2) + (a + 1)) * (pow(N , 2) - N))\n",
        "        a2 = b - c\n",
        "        a3 = c\n",
        "        a4 = 0\n",
        "    return a1,a2,a3,a4\n",
        "\n",
        "\n",
        "def nuFunction(fw, i, j, mg, x_bar, y_bar, teta):\n",
        "    M, N= shape(fw)\n",
        "    ll = 0\n",
        "    teta=pi*teta\n",
        "\n",
        "    matR = array([[math.cos(teta).real, math.sin(teta).real], [-math.sin(teta).real, math.cos(teta).real]])\n",
        "    #print(shape(matR))\n",
        "    #print(matR)\n",
        "    for x in range (0,M):\n",
        "        for y in range(0,N):\n",
        "\n",
        "            a1 = pow(((((x - x_bar) * matR[0, 0] + (y - y_bar) * matR[0, 1]) * sqrt(1 / mg)) + (M / 2)), i)\n",
        "            b1 = pow(((((x - x_bar) * matR[1, 0] + (y - y_bar) * matR[1, 1]) * sqrt(1 / mg)) + (N / 2)) ,j)\n",
        "            #print(\"a1\",a1)\n",
        "            #print(\"b1\", b1)\n",
        "            invar = a1 * b1\n",
        "            ll = ll + (invar) * fw[x, y]\n",
        "    nu=pow(ll * mg, -1)\n",
        "\n",
        "    return  nu\n",
        "\n",
        "def Qw2D(n, m, fw, mg, x_bar, y_bar, teta, alpha1, beta1, alpha2, beta2):\n",
        "    moment = 0;\n",
        "    M, N = shape(fw);\n",
        "    a = aCoef(n, alpha1, beta1, M);\n",
        "    b = aCoef(m, alpha2, beta2, N)\n",
        "    ghon = ghoHahn(n, alpha1, beta1, N);\n",
        "    ghom = ghoHahn(m, alpha2, beta2, N);\n",
        "    # print(moment)\n",
        "\n",
        "    dd = ghon * ghom\n",
        "    mmm = Decimal(sqrt(dd))\n",
        "\n",
        "    for i in range(0,n+1):\n",
        "        for j in range(0,m+1):\n",
        "\n",
        "            mom=a[i]*b[j] * nuFunction(fw, i, j, mg, x_bar, y_bar,teta)\n",
        "            moment = moment + Decimal(Decimal(mom) * Decimal(mmm))\n",
        "    #moment = Decimal(Decimal(moment) * Decimal(mmm))\n",
        "    #print(moment)\n",
        "    return float(moment)\n",
        "\n",
        "\n",
        "def momentGeometrique2D(fw, i, j):\n",
        "    M,N= shape(fw)\n",
        "    mt = 0;\n",
        "    for x in range(0,M):\n",
        "        for y in range(0,N):\n",
        "            mt = mt + pow(x,i) * pow(y,j) * fw[x, y];\n",
        "    return mt\n",
        "\n",
        "\n",
        "def momentGeometriqueInvariant2D(fw, i, j, x_bar, y_bar):\n",
        "    M, N = shape(fw)\n",
        "    moment = 0;\n",
        "    for x in range(0,M):\n",
        "        for y in range(0,N):\n",
        "            moment = moment + pow((x - x_bar) , i) * pow((y - y_bar),j) * fw[x, y]\n",
        "\n",
        "\n",
        "    return moment\n",
        "\n",
        "def getTetaTeague(a,b,c):\n",
        "\n",
        "\n",
        "    if(a==0 and b-c==0):\n",
        "         teta=0;\n",
        "    elif(a==0 and b-c>0):\n",
        "        teta=45;\n",
        "    elif(a==0 and b-c<0):\n",
        "        teta=-45;\n",
        "    elif(a>0 and b-c==0):\n",
        "        teta=0;\n",
        "    elif(a<0 and b-c==0):\n",
        "        teta=-90;\n",
        "    elif(a>0 and b-c>0):\n",
        "        teta=(1/2)*math.atan(pi*2*a/(b-c));\n",
        "    elif(a>0 and b-c<0):\n",
        "        teta=(1/2)*math.atan(pi*2*a/(b-c));\n",
        "    elif(a<0 and b-c>0):\n",
        "        teta=(1/2)*math.atan(pi*2*a/(b-c))+90;\n",
        "    elif(a<0 and b-c<0):\n",
        "        teta=(1/2)*math.atan(pi*2*a/(b-c))-90;\n",
        "\n",
        "    return teta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def getMatrixMoments(Mt, ordre, Poly):\n",
        "    n, m = shape(Mt)\n",
        "    #Poly=load('Poly.npy')\n",
        "    #A = HahnPolynome(ordre, n, a1, b1)\n",
        "    #B = HahnPolynome(ordre, n, a2, b2)\n",
        "    A=Poly[0:ordre+1,:]\n",
        "    B=A\n",
        "    momentD = matmul(A, Mt)\n",
        "    momentD = matmul(momentD, transpose(B));\n",
        "    #print(\"momentD\", shape(momentD))\n",
        "    moments=reshape(momentD,[-1, (ordre+1)*(ordre+1)])\n",
        "\n",
        "    return (moments)\n",
        "def getMatrixMomentsSansReshape(Mt, ordre, Poly):\n",
        "    MM, NN, LL = shape(Mt)\n",
        "    #print(\"size image:\",MM, NN, LL)\n",
        "    K111 = Poly\n",
        "    K222 = K111\n",
        "    K333 = K111\n",
        "    # K222 = HahnPolynome(ordre, n, a2, b2)\n",
        "    # K333=HahnPolynome(ordre, n, a3, b3)\n",
        "    ordre = ordre + 1\n",
        "    MMM = zeros([ordre, ordre, LL])\n",
        "\n",
        "    for i in range(0, LL):\n",
        "        MMM[:, :, i] = matmul(K111, matmul(Mt[:, :, i], transpose(K222)))\n",
        "\n",
        "    MMMM = zeros((LL, ordre, ordre))\n",
        "    for i in range(0, ordre):\n",
        "        for j in range(0, ordre):\n",
        "            for k in range(0, LL):\n",
        "                MMMM[k, j, i] = MMM[i, j, k]\n",
        "\n",
        "    momentD = zeros((ordre, ordre, ordre))\n",
        "    for z in range(0, ordre):\n",
        "        momentD[:, :, z] = (matmul(K333, MMMM[:, :, z]))\n",
        "\n",
        "    return (momentD)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def getBatchMoment3DSansResahpe(batch,ordre,Poly):\n",
        "    K,L,M,N,MM=shape(batch)\n",
        "\n",
        "    batchM=zeros((K,(ordre+1),(ordre+1),(ordre+1),1))\n",
        "    #print('calcul moments', shape(batch))\n",
        "    for i in range(0,K):\n",
        "        #A=zeros((1,10,1))\n",
        "       # print('calcul moments',shape(batch[i,:,:,0]))\n",
        "        A=getMatrixMomentsSansReshape(batch[i,:,:,:,0], ordre,Poly)\n",
        "        #B=reshape(A,1,9)\n",
        "        #B = transpose(A);\n",
        "        #print(\"shape\",shape(A))\n",
        "\n",
        "        batchM[i,:,:,:,0]=A\n",
        "\n",
        "    return batchM\n",
        "\n",
        "def getMatrixMomentsSansReshape2D(Mt, ordre, Poly):\n",
        "    n, m = shape(Mt)\n",
        "    # Poly=load('Poly.npy')\n",
        "    # A = HahnPolynome(ordre, n, a1, b1)\n",
        "    # B = HahnPolynome(ordre, n, a2, b2)\n",
        "    A = Poly[0:ordre + 1, :]\n",
        "    B = A\n",
        "    momentD = matmul(A, Mt)\n",
        "    momentD = matmul(momentD, transpose(B));\n",
        "    # print(\"momentD\", shape(momentD))\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    return momentD\n",
        "  \n",
        "\n",
        "def getMatrixMomentsWithReshape2D(Mt, ordre, Poly):\n",
        "    n, m = shape(Mt)\n",
        "    # Poly=load('Poly.npy')\n",
        "    # A = HahnPolynome(ordre, n, a1, b1)\n",
        "    # B = HahnPolynome(ordre, n, a2, b2)\n",
        "    A = Poly[0:ordre + 1, :]\n",
        "    B = A\n",
        "    momentD = matmul(A, Mt)\n",
        "    momentD = matmul(momentD, transpose(B));\n",
        "    # print(\"momentD\", shape(momentD))\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    return reshape(momentD,((ordre + 1)*(ordre + 1)))\n",
        "\n",
        "def getMatrixMomentsWithReshape2DV2(Mt, ordre, Poly1,Poly2):\n",
        "    n, m = shape(Mt)\n",
        "    # Poly=load('Poly.npy')\n",
        "    # A = HahnPolynome(ordre, n, a1, b1)\n",
        "    # B = HahnPolynome(ordre, n, a2, b2)\n",
        "    A = Poly1[0:ordre + 1, :]\n",
        "    B = Poly2[0:ordre + 1, :]\n",
        "    momentD = matmul(A, Mt)\n",
        "    momentD = matmul(momentD, transpose(B));\n",
        "    # print(\"momentD\", shape(momentD))\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    return reshape(momentD,((ordre + 1),(ordre + 1)))\n",
        "  \n",
        "def getPatternImageHahn(ordre1,ordre2 ,size, a1, b1, a2, b2):\n",
        "\n",
        "    A=HahnPolynome(ordre1, size, a1, b1)\n",
        "    B = HahnPolynome(ordre2, size, a2, b2)\n",
        "    A1 = ones((1, size))\n",
        "    B1 = ones((1, size))\n",
        "    A1[0, :] = A[ordre1, :]\n",
        "    B1[0, :] = B[ordre2, :]\n",
        "\n",
        "    pattern = matmul(transpose(A1), B1);\n",
        "\n",
        "    return pattern\n",
        "  \n",
        "def reconstructionImage2D(Mt, ordre, Poly):\n",
        "    n, m = shape(Mt)\n",
        "    # Poly=load('Poly.npy')\n",
        "    # A = HahnPolynome(ordre, n, a1, b1)\n",
        "    # B = HahnPolynome(ordre, n, a2, b2)\n",
        "    A = Poly[0:ordre + 1, :]\n",
        "    B = A\n",
        "    momentD = matmul(transpose(A), Mt)\n",
        "    momentD = matmul(momentD, (B));\n",
        "    # print(\"momentD\", shape(momentD))\n",
        "\n",
        "\n",
        "    return (momentD)\n",
        "#pt.plot(transpose(Poly15))\n",
        "\n",
        "#pt.show()\n",
        "#P=HahnPolynome(50, 300, 5, 5)\n",
        "#save(\"Poly.npy\",P)\n",
        "#pt.plot(transpose(P))\n",
        "\n",
        "#pt.show()\n",
        "\n",
        "def imagesToMoment(dataM,ordre):\n",
        "  \n",
        "    n,m,l,k=dataM.shape\n",
        "    print(dataM.shape)\n",
        "    P1=HahnPolynome(ordre, m, 5, 5)\n",
        "    P2=HahnPolynome(ordre, l, 5, 5)\n",
        "  #n,m,l,k=dataM.shape\n",
        "    moments=[]\n",
        "    for i in range(n):\n",
        "        moment=zeros((ordre+1,ordre+1,1))\n",
        "        img=dataM[i,:,:,0]\n",
        "    #print(img.shape)\n",
        "        moment[:,:,0]=getMatrixMomentsWithReshape2DV2(dataM[i,:,:,0],ordre,P1,P2)\n",
        "        moments.append(moment)\n",
        "    return asarray(moments)\n",
        "ordre=17\n",
        "\n",
        "X_trainM=imagesToMoment(X_train,ordre)\n",
        "X_testM=imagesToMoment(X_test,ordre)\n",
        "\n",
        "print(X_testM.shape)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(10000, 18, 18, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MON5ESCBhWit"
      },
      "source": [
        "# **Spike SoftLIF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q21cW4cxK1-"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "import os\n",
        "\n",
        "import tensorflow.keras\n",
        "import nengo\n",
        "import numpy as np\n",
        "\n",
        "import nengo_extras.deepnetworks\n",
        "\n",
        "\n",
        "class SoftLIF(tensorflow.keras.layers.Layer):\n",
        "    def __init__(self, sigma=1., amplitude=1., tau_rc=0.02, tau_ref=0.002,\n",
        "                 noise_model='none', tau_s=0.005, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.sigma = sigma\n",
        "        self.amplitude = amplitude\n",
        "        self.tau_rc = tau_rc\n",
        "        self.tau_ref = tau_ref\n",
        "\n",
        "        if noise_model not in ('none', 'alpharc'):\n",
        "            raise ValueError(\"Unrecognized noise model\")\n",
        "        self.noise_model = noise_model\n",
        "\n",
        "        self.tau_s = tau_s\n",
        "        if abs(self.tau_rc - self.tau_s) < 1e-4:\n",
        "            raise ValueError(\"tau_rc and tau_s must be different\")\n",
        "\n",
        "        super(SoftLIF, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        from keras import backend as K\n",
        "        if K.backend() == 'tensorflow':\n",
        "            import tensorflow as tf\n",
        "            expm1 = tf.math.expm1\n",
        "            log1p = tf.math.log1p\n",
        "            where = tf.where\n",
        "        else:\n",
        "            import theano.tensor as tt\n",
        "            expm1 = tt.expm1\n",
        "            log1p = tt.log1p\n",
        "            where = tt.switch\n",
        "\n",
        "        # compute non-noisy output\n",
        "        xs = x / self.sigma\n",
        "        x_valid = xs > -20\n",
        "        xs_safe = where(x_valid, xs, K.zeros_like(xs))\n",
        "        j = K.softplus(xs_safe) * self.sigma\n",
        "        p = self.tau_ref + self.tau_rc*where(\n",
        "            x_valid, log1p(1/j), -xs - np.log(self.sigma))\n",
        "        r = self.amplitude/p\n",
        "\n",
        "        if self.noise_model == 'none':\n",
        "            return r\n",
        "        elif self.noise_model == 'alpharc':\n",
        "            # compute noisy output for forward pass\n",
        "            d = self.tau_rc - self.tau_s\n",
        "            u01 = K.random_uniform(K.shape(p))\n",
        "            t = u01 * p\n",
        "            q_rc = K.exp(-t / self.tau_rc)\n",
        "            q_s = K.exp(-t / self.tau_s)\n",
        "            r_rc1 = -expm1(-p / self.tau_rc)  # 1 - exp(-p/tau_rc)\n",
        "            r_s1 = -expm1(-p / self.tau_s)  # 1 - exp(-p/tau_s)\n",
        "\n",
        "            pt = where(p < 100*self.tau_s, (p - t)*(1 - r_s1), K.zeros_like(p))\n",
        "            qt = where(t < 100*self.tau_s, q_s*(t + pt), K.zeros_like(t))\n",
        "            rt = qt / (self.tau_s * d * r_s1**2)\n",
        "            rn = self.tau_rc*(q_rc/(d*d*r_rc1) - q_s/(d*d*r_s1)) - rt\n",
        "\n",
        "            # r + stop_gradient(rn - r) = rn on forward pass, r on backwards\n",
        "            return r + K.stop_gradient(self.amplitude*rn - r)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'sigma': self.sigma, 'amplitude': self.amplitude,\n",
        "                  'tau_rc': self.tau_rc, 'tau_ref': self.tau_ref}\n",
        "        base_config = super(SoftLIF, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "\n",
        "_custom_objects = {\n",
        "    'SoftLIF': SoftLIF\n",
        "}\n",
        "\n",
        "\n",
        "def load_model_pair(filepath, custom_objects=None):\n",
        "    if custom_objects is None:\n",
        "        custom_objects = {}\n",
        "\n",
        "    json_path = filepath + '.json'\n",
        "    h5_path = filepath + '.h5'\n",
        "\n",
        "    combined_customs = dict(_custom_objects)\n",
        "    combined_customs.update(custom_objects)\n",
        "\n",
        "    with open(json_path, 'r') as f:\n",
        "        model = keras.models.model_from_json(\n",
        "            f.read(), custom_objects=combined_customs)\n",
        "\n",
        "    model.load_weights(h5_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def save_model_pair(model, filepath, overwrite=False):\n",
        "    json_path = filepath + '.json'\n",
        "    h5_path = filepath + '.h5'\n",
        "\n",
        "    if not overwrite and os.path.exists(json_path):\n",
        "        raise ValueError(\"Path already exists: %r\" % filepath)\n",
        "\n",
        "    json_string = model.to_json()\n",
        "    with open(json_path, 'w') as f:\n",
        "        f.write(json_string)\n",
        "\n",
        "    model.save_weights(h5_path, overwrite=overwrite)\n",
        "\n",
        "\n",
        "\n",
        "def kmodel_compute_shapes(kmodel, input_shape):\n",
        "    assert isinstance(kmodel, keras.models.Sequential)\n",
        "\n",
        "    shapes = [input_shape]\n",
        "    for layer in kmodel.layers:\n",
        "        s = layer.compute_output_shape(shapes[-1])\n",
        "        shapes.append(s)\n",
        "\n",
        "    return shapes\n",
        "\n",
        "\n",
        "class SequentialNetwork(nengo_extras.deepnetworks.SequentialNetwork):\n",
        "\n",
        "    def __init__(self, model, synapse=None, lif_type='lif', **kwargs):\n",
        "        super(SequentialNetwork, self).__init__(**kwargs)\n",
        "\n",
        "        assert isinstance(model, keras.models.Sequential)\n",
        "        self.model = model\n",
        "        self.synapse = synapse\n",
        "        self.lif_type = lif_type\n",
        "\n",
        "        # -- build model\n",
        "        self.add_data_layer(np.prod(model.input_shape[1:]))\n",
        "        for layer in model.layers:\n",
        "            self._add_layer(layer)\n",
        "\n",
        "    def _add_layer(self, layer):\n",
        "        assert layer.input_mask is None\n",
        "        assert layer.input_shape[0] is None\n",
        "\n",
        "        layer_adder = {\n",
        "            keras.layers.Activation: self._add_activation_layer,\n",
        "            keras.layers.Dense: self._add_dense_layer,\n",
        "            keras.layers.Dropout: self._add_dropout_layer,\n",
        "            keras.layers.Flatten: self._add_flatten_layer,\n",
        "            keras.layers.Convolution2D: self._add_conv2d_layer,\n",
        "            keras.layers.AveragePooling2D: self._add_avgpool2d_layer,\n",
        "            keras.layers.MaxPooling2D: self._add_maxpool2d_layer,\n",
        "            keras.layers.noise.GaussianNoise: self._add_gaussian_noise_layer,\n",
        "            SoftLIF: self._add_softlif_layer,\n",
        "        }\n",
        "\n",
        "        for cls in type(layer).__mro__:\n",
        "            if cls in layer_adder:\n",
        "                return layer_adder[cls](layer)\n",
        "\n",
        "        raise NotImplementedError(\"Cannot build layer type %r\" %\n",
        "                                  type(layer).__name__)\n",
        "\n",
        "    def _add_dense_layer(self, layer):\n",
        "        weights, biases = layer.get_weights()\n",
        "        return self.add_full_layer(weights.T, biases, name=layer.name)\n",
        "\n",
        "    def _add_conv2d_layer(self, layer):\n",
        "        import keras.backend as K\n",
        "        shape_in = layer.input_shape[1:]\n",
        "        filters, biases = layer.get_weights()\n",
        "        strides = layer.strides\n",
        "\n",
        "        assert layer.data_format == 'channels_first'\n",
        "        nc, _, _ = shape_in\n",
        "        filters = np.transpose(filters, (3, 2, 0, 1))\n",
        "        if K.backend() == 'theano':\n",
        "            filters = filters[:, :, ::-1, ::-1]  # theano has flipped filters\n",
        "        filters = filters.copy()  # to make contiguous\n",
        "\n",
        "        nf, nc2, si, sj = filters.shape\n",
        "        assert nc == nc2, \"Filter channels must match input channels\"\n",
        "\n",
        "        if layer.padding == 'valid':\n",
        "            padding = (0, 0)\n",
        "        elif layer.padding == 'same':\n",
        "            padding = ((si - 1) / 2, (sj - 1) / 2)\n",
        "        else:\n",
        "            raise ValueError(\"Unrecognized padding %r\" % layer.padding)\n",
        "\n",
        "        conv = self.add_conv_layer(\n",
        "            shape_in, filters, biases, strides=strides, padding=padding,\n",
        "            border='floor', name=layer.name)\n",
        "        assert conv.size_out == np.prod(layer.output_shape[1:])\n",
        "        return conv\n",
        "\n",
        "    def _add_pool2d_layer(self, layer, kind=None):\n",
        "        shape_in = layer.input_shape[1:]\n",
        "        pool_size = layer.pool_size\n",
        "        strides = layer.strides\n",
        "        return self.add_pool_layer(shape_in, pool_size, strides=strides,\n",
        "                                   kind=kind, mode='valid', name=layer.name)\n",
        "\n",
        "    def _add_avgpool2d_layer(self, layer):\n",
        "        return self._add_pool2d_layer(layer, kind='avg')\n",
        "\n",
        "    def _add_maxpool2d_layer(self, layer):\n",
        "        return self._add_pool2d_layer(layer, kind='max')\n",
        "\n",
        "    def _add_activation_layer(self, layer):\n",
        "        if layer.activation is keras.activations.softmax:\n",
        "            return self._add_softmax_layer(layer)\n",
        "\n",
        "        # add normal activation layer\n",
        "        activation_map = {\n",
        "            keras.activations.relu: nengo.neurons.RectifiedLinear(),\n",
        "            keras.activations.sigmoid: nengo.neurons.Sigmoid(),\n",
        "            }\n",
        "        neuron_type = activation_map.get(layer.activation, None)\n",
        "        if neuron_type is None:\n",
        "            raise ValueError(\"Unrecognized activation type %r\"\n",
        "                             % layer.activation)\n",
        "\n",
        "        n = np.prod(layer.input_shape[1:])\n",
        "        return self.add_neuron_layer(\n",
        "            n, neuron_type=neuron_type, synapse=self.synapse,\n",
        "            gain=1, bias=0, name=layer.name)\n",
        "\n",
        "    def _add_softlif_layer(self, layer):\n",
        "        from .neurons import SoftLIFRate\n",
        "\n",
        "        taus = dict(tau_rc=layer.tau_rc, tau_ref=layer.tau_ref)\n",
        "        lif_type = self.lif_type.lower()\n",
        "        if lif_type == 'lif':\n",
        "            neuron_type = nengo.LIF(**taus)\n",
        "        elif lif_type == 'lifrate':\n",
        "            neuron_type = nengo.LIFRate(**taus)\n",
        "        elif lif_type == 'softlifrate':\n",
        "            neuron_type = SoftLIFRate(sigma=layer.sigma, **taus)\n",
        "        else:\n",
        "            raise KeyError(\"Unrecognized LIF type %r\" % self.lif_type)\n",
        "\n",
        "        n = np.prod(layer.input_shape[1:])\n",
        "        return self.add_neuron_layer(\n",
        "            n, neuron_type=neuron_type, synapse=self.synapse,\n",
        "            gain=1, bias=1, amplitude=layer.amplitude, name=layer.name)\n",
        "\n",
        "    def _add_softmax_layer(self, layer):\n",
        "        return None  # non-neural, we can do without it\n",
        "        # return self.add_softmax_layer(\n",
        "        #     np.prod(layer.input_shape[1:]), name=layer.name)\n",
        "\n",
        "    def _add_dropout_layer(self, layer):\n",
        "        return None  # keras scales by dropout rate, so we don't have to\n",
        "\n",
        "    def _add_flatten_layer(self, layer):\n",
        "        return None  # no computation, just reshaping, so ignore\n",
        "\n",
        "    def _add_gaussian_noise_layer(self, layer):\n",
        "        return None  # no noise during testing\n",
        "\n",
        "\n",
        "\n",
        "def LSUVinit(kmodel, X, tol=0.1, t_max=50):\n",
        "    \"\"\"Layer-sequential unit-variance initialization.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] Mishkin, D., & Matas, J. (2016). All you need is a good init.\n",
        "       In ICLR 2016 (pp. 1-13).\n",
        "    \"\"\"\n",
        "    from keras.layers import Convolution2D, LocallyConnected2D\n",
        "    import keras.backend as K\n",
        "    # f = K.function([kmodel.layers[0].input, K.learning_phase()],\n",
        "    #                [klayer.output])\n",
        "\n",
        "    # --- orthogonalize weights\n",
        "    def orthogonalize(X):\n",
        "        assert X.ndim == 2\n",
        "        U, s, V = np.linalg.svd(X, full_matrices=False)\n",
        "        return np.dot(U, V)\n",
        "\n",
        "    for layer in kmodel.layers:\n",
        "        weights = layer.get_weights()\n",
        "        if len(weights) == 0:\n",
        "            continue\n",
        "\n",
        "        W, b = weights\n",
        "        if isinstance(layer, Convolution2D):\n",
        "            Wv = W.reshape(W.shape[0], -1)\n",
        "        elif isinstance(layer, LocallyConnected2D):\n",
        "            Wv = W.reshape(-1, W.shape[-1])\n",
        "        else:\n",
        "            assert W.ndim == 2\n",
        "            Wv = W\n",
        "\n",
        "        Wv[:] = orthogonalize(Wv)\n",
        "        layer.set_weights((W, b))\n",
        "\n",
        "    # --- adjust variances\n",
        "    s_input = kmodel.layers[0].input\n",
        "    for layer in kmodel.layers:\n",
        "        weights = layer.get_weights()\n",
        "        if len(weights) == 0:\n",
        "            continue\n",
        "\n",
        "        W, b = weights\n",
        "        f = K.function([s_input, K.learning_phase()], [layer.output])\n",
        "        learning_phase = 0  # 0 == testing, 1 == training\n",
        "\n",
        "        for i in range(t_max):\n",
        "            Y = f([X, learning_phase])[0]\n",
        "            Ystd = Y.std()\n",
        "            print(Ystd)\n",
        "            if abs(Ystd - 1) < tol:\n",
        "                break\n",
        "\n",
        "            W /= Ystd\n",
        "            layer.set_weights((W, b))\n",
        "        else:\n",
        "            print(\"Layer %r did not converge after %d iterations (Ystd=%0.3e)\"\n",
        "                  % (layer.name, t_max, Ystd))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYf7a4pZxK4G"
      },
      "source": [
        "## **ARCHITECTURE ZSCNN Z IMAGE score 99.68** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIbG-dyBxK4I"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import (Add,Reshape,Activation, Conv2D,GlobalAveragePooling2D, Dense, Dropout, Flatten,AvgPool2D,MaxPooling2D,LeakyReLU,Input,Concatenate,Subtract)\n",
        "from tensorflow.python.keras.layers.noise import GaussianNoise\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "#import tensorflow.contrib as tf_contrib\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import keras\n",
        "from random import randint\n",
        "data_format = 'channels_last'\n",
        "kernel_size1 = (5, 5)  # shape of each convolutional filter\n",
        "kernel_size2 = (3, 3)\n",
        "kernel_size3 = (1, 1)\n",
        "num_classes = 10\n",
        "weight_decay=1e-12\n",
        "\n",
        "#activity_regularizer=keras.regularizers.l1(0.01)\n",
        "#weight_init = tf_contrib.layers.variance_scaling_initializer()\n",
        "#weight_regularizer = tf_contrib.layers.l2_regularizer(0.0001)\n",
        "depth=3\n",
        "\n",
        "\n",
        "softlif_params = dict(sigma=0.01, amplitude=0.063, tau_rc=0.059, tau_ref=0.008)\n",
        "\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "    # construct Keras model\n",
        "def drplayer(x,x1,x2):\n",
        "    x1=Dropout(0.25)(x1)\n",
        "    x2=Dropout(0.25)(x2)\n",
        "    x=Dropout(0.25)(x)\n",
        "\n",
        "    return x,x1,x2\n",
        "\n",
        "def reductionDemension(X,X1,X2):\n",
        "    x1=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(X1)\n",
        "    x2=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(X2)\n",
        "    x=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(X)\n",
        "    return x,x1,x2\n",
        "\n",
        "def block_level1(inputX,l1,l2):\n",
        "    inputX=BatchNormalization()(inputX)\n",
        "    x1=Conv2D(l1, kernel_size1, padding='same', strides=(1, 1), data_format=data_format, kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX)\n",
        "    x2=Conv2D(l2, kernel_size2, padding='same', strides=(1, 1), data_format=data_format, kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX)\n",
        "    x=Conv2D(l2, kernel_size3, padding='same', strides=(1, 1), data_format=data_format, kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX)\n",
        "    \n",
        "    \n",
        "    x1=SoftLIF(**softlif_params)(x1)\n",
        "    x2=SoftLIF(**softlif_params)(x2)\n",
        "    x=SoftLIF(**softlif_params)(x)\n",
        "    \n",
        "    \n",
        "    return x,x1,x2\n",
        "\n",
        "def block_tri_level(inputX,inputX1,inputX2,l1,l2):\n",
        "    inputX1=BatchNormalization()(inputX1)\n",
        "    inputX2=BatchNormalization()(inputX2)\n",
        "    inputX=BatchNormalization()(inputX)\n",
        "\n",
        "    C=Concatenate(axis=3)([inputX1,inputX2])\n",
        "   \n",
        "    x1=Conv2D(l1, kernel_size1, padding='same',activation=\"relu\", data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay), strides=(1, 1))(C)\n",
        "    x2=Conv2D(l2, kernel_size2, padding='same',activation=\"relu\", data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay),strides=(1, 1))(inputX2)\n",
        "    x=Conv2D(l2, kernel_size3, padding='same',activation=\"relu\", data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay),strides=(1, 1))(inputX)\n",
        "  \n",
        "    \n",
        "    \n",
        "    x1=SoftLIF(**softlif_params)(x1)\n",
        "    x2=SoftLIF(**softlif_params)(x2)\n",
        "    x=SoftLIF(**softlif_params)(x)\n",
        "    \n",
        "    \n",
        "    return x,x1,x2\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "def make_model(input_shape):\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "  x=GaussianNoise(0.1, input_shape=input_shape)(inputs)\n",
        "\n",
        "  xx,x0,x1=block_level1(inputs,256,128)\n",
        "  xx,x0,x1=drplayer(xx,x0,x1)\n",
        "  #x111=Concatenate(axis=3)([x0,x1])\n",
        "  for i in range(depth):\n",
        "    xx,x0,x1=block_tri_level(xx,x0,x1,128,64)\n",
        "    xx,x0,x1=reductionDemension(xx,x0,x1)\n",
        "    xx,x0,x1=drplayer(xx,x0,x1)\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  x=Concatenate(axis=3)([x0,xx,x1])\n",
        " \n",
        "  \n",
        "\n",
        "  \n",
        "  x=(Flatten()(x))\n",
        "  \n",
        "   \n",
        "\n",
        "  \n",
        "  x=Dense(1000,kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
        "  x=SoftLIF(**softlif_params)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.25)(x)\n",
        "  \n",
        "  x=Dense(256,kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
        "  x=SoftLIF(**softlif_params)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  \n",
        "  x=Dropout(0.25)(x)\n",
        "  x=Dense(num_classes, activation='softmax',kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
        "\n",
        "  kmodel = Model(inputs, x)\n",
        "  \n",
        "  kmodel.summary()\n",
        "  \n",
        "  return kmodel\n",
        "\n",
        "\n",
        "\n",
        "#lrr=1e-4\n",
        "## compile and fit Keras model\n",
        "#optimizer = tensorflow.keras.optimizers.Nadam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "#kmodel.compile(loss='categorical_crossentropy',           optimizer=optimizer,         metrics=['accuracy'])\n",
        "#kmodelHistory=kmodel.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "#score = kmodel.evaluate(X_test, Y_test, verbose=0)\n",
        "#print('Test score:', score[0])\n",
        "#print('Test accuracy:', score[1])\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbpVEhaZjpqo",
        "outputId": "18be1d2a-30a1-4833-83d6-b815879f2750"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "epochs=80\n",
        "learning_rate=1e-4\n",
        "batch_size=120\n",
        "data_augmentation=False\n",
        "#strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "inputImag=X_train.shape[1:]\n",
        "print(\"profondeur:\",depth)\n",
        "# prepare model model saving directory\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'MNIST_ZNET_model.{epoch:03d}.h5' \n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "import math\n",
        "def step_decay(epoch):\n",
        "  initial_lrate = 0.01\n",
        "  drop = 0.5\n",
        "  epochs_drop =10.0\n",
        "  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
        "  #if lrate<0.00015:\n",
        "  #  lrate=0.00073\n",
        "  print('Learning rate: ', lrate)\n",
        "  return lrate\n",
        "\n",
        "lrate=LearningRateScheduler(step_decay) \n",
        "# prepare callbacks for model saving and for learning rate reducer\n",
        "\n",
        "\n",
        "\n",
        "#callbacks = [checkpoint, lr_scheduler]\n",
        "\n",
        "#callbacks = [lr_scheduler]\n",
        "\n",
        "lrr=1e-4\n",
        "#epochs=150\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-2\n",
        "    if epoch > 180:\n",
        "        lr *= 5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 140:\n",
        "        lr *= 3e-2\n",
        "    elif epoch > 100:\n",
        "        lr *= 5e-2\n",
        "    elif epoch > 60:\n",
        "        lr *= 1e-1\n",
        "    elif epoch > 20:\n",
        "        lr *= 3e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "def lr_schedule_1(epoch):\n",
        "    if epoch > 70:\n",
        "        lrate = 0.00001\n",
        "    if epoch > 63:\n",
        "        lrate = 0.00002\n",
        "    elif epoch > 57:\n",
        "        lrate = 0.00003\n",
        "    elif epoch > 45:\n",
        "        lrate = 0.00005\n",
        "    elif epoch > 26:\n",
        "        lrate = 0.0001\n",
        "    elif epoch > 23:\n",
        "        lrate = 0.0002\n",
        "    elif epoch > 18:\n",
        "        lrate = 0.0003\n",
        "    elif epoch > 13:\n",
        "        lrate = 0.0005\n",
        "    else:\n",
        "        lrate = 0.001\n",
        "    print('Learning rate: ', lrate)     \n",
        "    return lrate\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "\n",
        "lr_schedule_0 = LearningRateScheduler(lr_schedule_1)\n",
        "callbacks = [lr_reducer, lr_schedule_0,checkpoint]\n",
        "\n",
        "\n",
        "model =  make_model(inputImag)\n",
        "model.compile(\n",
        "      optimizer=tf.keras.optimizers.Nadam(lr=lr_schedule_1(0),beta_1=0.9, beta_2=0.999, epsilon=1e-09 ),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "#TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "#modelTPU = tf.contrib.tpu.keras_to_tpu_model(model,strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "#        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "#modelTPU=model\n",
        "  \n",
        "model.fit(\n",
        "      X_train.astype(np.float32), Y_train.astype(np.float32),\n",
        "      epochs=epochs,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(X_test.astype(np.float32), Y_test.astype(np.float32)), verbose=1,callbacks=callbacks)\n",
        "#validation_freq=5,\n",
        "\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "profondeur: 3\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 28, 28, 1)    4           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 256)  6656        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 128)  1280        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif (SoftLIF)              (None, 28, 28, 256)  0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_1 (SoftLIF)            (None, 28, 28, 128)  0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 28, 28, 256)  0           soft_lif[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 28, 28, 128)  0           soft_lif_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 28, 256)  1024        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 28, 28, 128)  512         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 128)  256         batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 28, 28, 384)  0           batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_2 (SoftLIF)            (None, 28, 28, 128)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 128)  1228928     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 64)   73792       batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 28, 28, 128)  0           soft_lif_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_3 (SoftLIF)            (None, 28, 28, 128)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_4 (SoftLIF)            (None, 28, 28, 64)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 28, 28, 128)  512         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 14, 14, 128)  0           soft_lif_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 14, 14, 64)   0           soft_lif_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 64)   8256        batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 14, 14, 128)  0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 14, 14, 64)   0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_5 (SoftLIF)            (None, 28, 28, 64)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 14, 14, 128)  512         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 14, 14, 64)   256         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 14, 14, 64)   0           soft_lif_5[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 14, 14, 192)  0           batch_normalization_4[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 14, 14, 64)   0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 14, 14, 128)  614528      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 14, 14, 64)   36928       batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 14, 14, 64)   256         dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_6 (SoftLIF)            (None, 14, 14, 128)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_7 (SoftLIF)            (None, 14, 14, 64)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 14, 14, 64)   4160        batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 128)    0           soft_lif_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 64)     0           soft_lif_7[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_8 (SoftLIF)            (None, 14, 14, 64)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 128)    0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 7, 7, 64)     0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 64)     0           soft_lif_8[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 7, 7, 128)    512         dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 7, 7, 64)     256         dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 7, 7, 64)     0           average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 7, 7, 192)    0           batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 7, 7, 64)     256         dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 128)    614528      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 7, 7, 64)     4160        batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 7, 7, 64)     36928       batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_9 (SoftLIF)            (None, 7, 7, 128)    0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_11 (SoftLIF)           (None, 7, 7, 64)     0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_10 (SoftLIF)           (None, 7, 7, 64)     0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 4, 4, 128)    0           soft_lif_9[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 4, 4, 64)     0           soft_lif_11[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 4, 4, 64)     0           soft_lif_10[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 4, 4, 128)    0           average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 4, 4, 64)     0           average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 4, 4, 64)     0           average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 4, 4, 256)    0           dropout_9[0][0]                  \n",
            "                                                                 dropout_11[0][0]                 \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4096)         0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1000)         4097000     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_12 (SoftLIF)           (None, 1000)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 1000)         4000        soft_lif_12[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 1000)         0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          256256      dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_13 (SoftLIF)           (None, 256)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 256)          1024        soft_lif_13[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 256)          0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           2570        dropout_13[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 6,995,350\n",
            "Trainable params: 6,990,788\n",
            "Non-trainable params: 4,562\n",
            "__________________________________________________________________________________________________\n",
            "Learning rate:  0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 271s 452ms/step - loss: 0.1994 - accuracy: 0.9386 - val_loss: 0.0798 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.97440, saving model to /content/saved_models/MNIST_ZNET_model.001.h5\n",
            "Epoch 2/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 224s 448ms/step - loss: 0.0675 - accuracy: 0.9791 - val_loss: 0.0474 - val_accuracy: 0.9850\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.97440 to 0.98500, saving model to /content/saved_models/MNIST_ZNET_model.002.h5\n",
            "Epoch 3/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 224s 447ms/step - loss: 0.0519 - accuracy: 0.9840 - val_loss: 0.0447 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.98500\n",
            "Epoch 4/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 224s 448ms/step - loss: 0.0428 - accuracy: 0.9863 - val_loss: 0.0360 - val_accuracy: 0.9888\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.98500 to 0.98880, saving model to /content/saved_models/MNIST_ZNET_model.004.h5\n",
            "Epoch 5/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 224s 447ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0219 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.98880 to 0.99160, saving model to /content/saved_models/MNIST_ZNET_model.005.h5\n",
            "Epoch 6/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 225s 449ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0314 - val_accuracy: 0.9901\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.99160\n",
            "Epoch 7/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 225s 449ms/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 0.0317 - val_accuracy: 0.9896\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.99160\n",
            "Epoch 8/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 225s 450ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.0244 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.99160\n",
            "Epoch 9/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 225s 450ms/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 0.0358 - val_accuracy: 0.9882\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.99160\n",
            "Epoch 10/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 225s 450ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.0204 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.99160 to 0.99350, saving model to /content/saved_models/MNIST_ZNET_model.010.h5\n",
            "Epoch 11/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 225s 450ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 0.0438 - val_accuracy: 0.9869\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.99350\n",
            "Epoch 12/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 225s 451ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0240 - val_accuracy: 0.9926\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99350\n",
            "Epoch 13/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 225s 450ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0150 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.99350 to 0.99460, saving model to /content/saved_models/MNIST_ZNET_model.013.h5\n",
            "Epoch 14/80\n",
            "Learning rate:  0.001\n",
            "500/500 [==============================] - 225s 451ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.0169 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99460\n",
            "Epoch 15/80\n",
            "Learning rate:  0.0005\n",
            " 44/500 [=>............................] - ETA: 3:16 - loss: 0.0212 - accuracy: 0.9920"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "8eICrC33xK4b",
        "outputId": "c5931295-e22f-41e0-f0c0-0cf7072e5dad"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "score = kmodel.evaluate(test_images, yt, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "accuracy = kmodelHistory.history['acc']\n",
        "val_accuracy = kmodelHistory.history['val_acc']\n",
        "loss = kmodelHistory.history['loss']\n",
        "val_loss = kmodelHistory.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, '-', label='Training accuracy',linewidth=2)\n",
        "plt.plot(epochs, val_accuracy, 'g',c='red', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, '-', label='Training loss',linewidth=2)\n",
        "plt.plot(epochs, val_loss, 'b',c='red', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.02693131220564246\n",
            "Test accuracy: 0.9951\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUi6niV4ppVzu/wMT0DEDN91SmgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BApakXlqWey"
      },
      "source": [
        "# **Architecture With my activation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "H0KS2dGPq748",
        "outputId": "5ed8aa44-b22c-43e6-acda-bf163e4c91a2"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import (Activation, Conv2D,GlobalAveragePooling2D, Dense, Dropout, Flatten,AvgPool2D,MaxPooling2D,LeakyReLU,Input,Concatenate,Subtract)\n",
        "from tensorflow.python.keras.layers.noise import GaussianNoise\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "\n",
        "# --- Parameters\n",
        "np.random.seed(1)\n",
        "\n",
        "run_in_theano = False\n",
        "#use_ocl = True\n",
        "presentation_time = 0.15\n",
        "n_presentations = 100\n",
        "subtract_pixel_mean = True\n",
        "# --- Load data\n",
        "img_rows, img_cols = 32, 32\n",
        "n_classes = 10\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "data_format = 'channels_last'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "X_train = X_train.astype('float32') #/ 255.\n",
        "X_test = X_test.astype('float32') #/ 255.\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    mean=np.mean(X_train)\n",
        "    std=np.std(X_train)\n",
        "    X_test=(X_test-mean)/std\n",
        "    X_train=(X_train-mean)/std\n",
        "\n",
        "\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "Y_train = np_utils.to_categorical(Y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(Y_test, n_classes)\n",
        "\n",
        "print('x_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "print('y_train shape:', Y_train.shape)\n",
        "\n",
        "\n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 10)\n",
            "(32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QLwkyTkHqiTO",
        "outputId": "84095f07-5212-46d7-ce0e-cb3ad47f020e"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "alpha=.025\n",
        "beta=.05\n",
        "def sig(x):\n",
        "    #return tf.math.softplus(x)* tf.math.tanh(tf.math.softplus(x))\n",
        "    return tf.math.softplus(x)* tf.math.sigmoid(tf.math.softplus(x))\n",
        "    #return K.softplus(x)\n",
        "def Myactiv(x):\n",
        "    #return (K.sigmoid(beta * x) * alpha *x)\n",
        "    #return K.relu(K.exp(x*alpha/2))\n",
        "    #return (K.sigmoid( x*.092) )\n",
        "    return sig(x)\n",
        "    #return (K.relu(x) )\n",
        "    #return (alpha*x * K.sigmoid(x*alpha))- K.relu(x)\n",
        "\n",
        "def LiSHT(x):\n",
        "    return x * K.tanh(x)\n",
        "\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({'Myactiv': Activation(Myactiv)})\n",
        "#get_custom_objects().update({'LiSHT': Activation(LiSHT)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "9A56PKI5qBeU",
        "outputId": "6fadefcf-004f-4df8-9659-503bc0b8ace4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import (Add,Reshape,Activation, Conv2D,GlobalAveragePooling2D, Dense, Dropout, Flatten,AvgPool2D,MaxPooling2D,LeakyReLU,Input,Concatenate,Subtract)\n",
        "from tensorflow.python.keras.layers.noise import GaussianNoise\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "#import tensorflow.contrib as tf_contrib\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import keras\n",
        "from random import randint\n",
        "data_format = 'channels_last'\n",
        "kernel_size1 = (5, 5)  # shape of each convolutional filter\n",
        "kernel_size2 = (3, 3)\n",
        "kernel_size3 = (1, 1)\n",
        "num_classes = 10\n",
        "weight_decay=1e-12\n",
        "\n",
        "#activity_regularizer=keras.regularizers.l1(0.01)\n",
        "#weight_init = tf_contrib.layers.variance_scaling_initializer()\n",
        "#weight_regularizer = tf_contrib.layers.l2_regularizer(0.0001)\n",
        "depth=6\n",
        "#reg=keras.regularizers.l2(weight_decay)\n",
        "reg=None\n",
        "softlif_params = dict(sigma=0.01, amplitude=0.063, tau_rc=0.059, tau_ref=0.008)\n",
        "\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "print(input_shape)\n",
        "print(np.shape(X_train), np.shape(Y_train) )\n",
        "print(np.shape(X_test), np.shape(Y_test) )\n",
        "\n",
        "\n",
        "    # construct Keras model\n",
        "def drplayer(x,x1,x2,val):\n",
        "    x1=Dropout(val)(x1)\n",
        "    x2=Dropout(val)(x2)\n",
        "    x=Dropout(val)(x)\n",
        "\n",
        "    return x,x1,x2\n",
        "\n",
        "def reductionDemension(X,X1,X2):\n",
        "    x1=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(X1)\n",
        "    x2=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(X2)\n",
        "    x=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(X)\n",
        "    return x,x1,x2\n",
        "\n",
        "def block_level1(inputX,l1,l2):\n",
        "    inputX=BatchNormalization()(inputX)\n",
        "    x1=Conv2D(l1, kernel_size1, padding='same', strides=(1, 1), data_format=data_format, kernel_regularizer=reg)(inputX)\n",
        "    x2=Conv2D(l2, kernel_size2, padding='same', strides=(1, 1), data_format=data_format, kernel_regularizer=reg)(inputX)\n",
        "    x=Conv2D(l2, kernel_size3, padding='same', strides=(1, 1), data_format=data_format, kernel_regularizer=reg)(inputX)\n",
        "    \n",
        "    \n",
        "    x1=SoftLIF(**softlif_params)(x1)\n",
        "    x2=SoftLIF(**softlif_params)(x2)\n",
        "    x=SoftLIF(**softlif_params)(x)\n",
        "    \n",
        "    \n",
        "    return x,x1,x2\n",
        "\n",
        "def block_tri_level(inputX,inputX1,inputX2,l1,l2):\n",
        "    inputX1=BatchNormalization(axis=-1)(inputX1)\n",
        "    inputX2=BatchNormalization(axis=-1)(inputX2)\n",
        "    inputX=BatchNormalization(axis=-1)(inputX)\n",
        "\n",
        "    C=Concatenate(axis=3)([inputX1,inputX2])\n",
        "   \n",
        "    x1=Conv2D(l1, kernel_size1, padding='same',activation=Myactiv, data_format=data_format,kernel_regularizer=reg, strides=(1, 1))(C)\n",
        "    x2=Conv2D(l2, kernel_size2, padding='same',activation=Myactiv, data_format=data_format,kernel_regularizer=reg,strides=(1, 1))(inputX2)\n",
        "    x=Conv2D(l2, kernel_size3, padding='same',activation=Myactiv, data_format=data_format,kernel_regularizer=reg,strides=(1, 1))(inputX)\n",
        "  \n",
        "    \n",
        "    \n",
        "    x1=SoftLIF(**softlif_params)(x1)\n",
        "    x2=SoftLIF(**softlif_params)(x2)\n",
        "    x=SoftLIF(**softlif_params)(x)\n",
        "    \n",
        "    \n",
        "    return x,x1,x2\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "val=.25\n",
        "nbfilters=16\n",
        "def make_model(input_shape):\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "  x=GaussianNoise(0.1, input_shape=input_shape)(inputs)\n",
        "\n",
        "  xx,x0,x1=block_level1(inputs,nbfilters,nbfilters)\n",
        "  xx,x0,x1=drplayer(xx,x0,x1,val)\n",
        "  #x111=Concatenate(axis=3)([x0,x1])\n",
        "  l=0\n",
        "  for i in range(depth):\n",
        "    if depth%2==0:\n",
        "      l+=2\n",
        "    xx,x0,x1=block_tri_level(xx,x0,x1,nbfilters*l,nbfilters*l)\n",
        "    xx,x0,x1=reductionDemension(xx,x0,x1)\n",
        "    xx,x0,x1=drplayer(xx,x0,x1,val)\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  x=Concatenate(axis=3)([x0,xx,x1])\n",
        " \n",
        "  \n",
        "\n",
        "  \n",
        "  x=(Flatten()(x))\n",
        "  \n",
        "   \n",
        "\n",
        "  \n",
        "  x=Dense(512,kernel_regularizer=reg)(x)\n",
        "  x=SoftLIF(**softlif_params)(x)\n",
        "  #x=BatchNormalization()(x)\n",
        "  x=Dropout(0.25)(x)\n",
        "  \n",
        "  x=Dense(256,kernel_regularizer=reg)(x)\n",
        "  #x=SoftLIF(**softlif_params)(x)\n",
        "  #x=BatchNormalization()(x)\n",
        "  \n",
        "  x=Dropout(0.5)(x)\n",
        "  x=Dense(num_classes, activation='softmax',kernel_regularizer=reg)(x)\n",
        "\n",
        "  kmodel = Model(inputs, x)\n",
        "  \n",
        "  kmodel.summary()\n",
        "  \n",
        "  return kmodel\n",
        "\n",
        "\n",
        "\n",
        "#lrr=1e-4\n",
        "## compile and fit Keras model\n",
        "#optimizer = tensorflow.keras.optimizers.Nadam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "#kmodel.compile(loss='categorical_crossentropy',           optimizer=optimizer,         metrics=['accuracy'])\n",
        "#kmodelHistory=kmodel.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "#score = kmodel.evaluate(X_test, Y_test, verbose=0)\n",
        "#print('Test score:', score[0])\n",
        "#print('Test accuracy:', score[1])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-97aeb34bacb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8idWq-gFrQPF",
        "outputId": "3a558604-b982-47f0-930f-cd0a1bf6019a"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "epochs=200\n",
        "learning_rate=3e-4\n",
        "batch_size=128\n",
        "data_augmentation=True\n",
        "#strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "inputImag=X_train.shape[1:]\n",
        "print(\"profondeur:\",depth)\n",
        "# prepare model model saving directory\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_ZNET_model.{epoch:03d}.h5' \n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "import math\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.01\n",
        "    drop = 0.5\n",
        "    epochs_drop =10.0\n",
        "    lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
        "  #if lrate<0.00015:\n",
        "  #  lrate=0.00073\n",
        "    print('Learning rate: ', lrate)\n",
        "    return lrate\n",
        "\n",
        "lrate=LearningRateScheduler(step_decay) \n",
        "# prepare callbacks for model saving and for learning rate reducer\n",
        "\n",
        "\n",
        "\n",
        "#callbacks = [checkpoint, lr_scheduler]\n",
        "\n",
        "#callbacks = [lr_scheduler]\n",
        "\n",
        "lrr=1e-4\n",
        "#epochs=150\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-2\n",
        "    if epoch > 180:\n",
        "        lr *= 0.1e-3\n",
        "    #elif epoch > 170:\n",
        "    #    lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 0.3e-3\n",
        "    elif epoch > 130:\n",
        "        lr *= 0.1e-2\n",
        "    elif epoch > 110:\n",
        "        lr *= 0.3e-2\n",
        "    elif epoch > 90:\n",
        "        lr *= 0.1e-1\n",
        "    elif epoch > 70:\n",
        "        lr *= 0.3e-1\n",
        "    elif epoch > 40:\n",
        "        lr *= 1e-1\n",
        "    elif epoch > 20:\n",
        "        lr *= 3e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "def lr_schedule_1(epoch):\n",
        "    if epoch > 26:\n",
        "        lrate = 0.0001\n",
        "    elif epoch > 23:\n",
        "        lrate = 0.0002\n",
        "    elif epoch > 18:\n",
        "        lrate = 0.0003\n",
        "    elif epoch > 13:\n",
        "        lrate = 0.0005\n",
        "    else:\n",
        "        lrate = 0.001\n",
        "         \n",
        "    return lrate\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "\n",
        "\n",
        "model =  make_model(inputImag)\n",
        "#model_optimizer=tensorflow.keras.optimizers.Nadam(lr=lr_schedule(0), beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "model_optimizer=tensorflow.keras.optimizers.Adam(lr=0.001,decay=0, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "model.compile(\n",
        "      optimizer=model_optimizer,\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "#model.compile(loss='categorical_crossentropy',\n",
        "#              optimizer=tensorflow.keras.optimizers.Adam(lr=lr_schedule(0)),\n",
        "#              metrics=['accuracy'])\n",
        "lr_schedule_0 = LearningRateScheduler(lr_schedule)\n",
        "callbacks = [lr_reducer, lr_schedule_0, checkpoint]\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(\n",
        "      X_train, Y_train,\n",
        "      epochs=epochs,\n",
        "      batch_size=120,\n",
        "      validation_data=(X_test, Y_test), verbose=1,shuffle=True,callbacks=callbacks)\n",
        "\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        \n",
        "       \n",
        "        #shear_range=0.2,\n",
        "        rotation_range=15,\n",
        "        horizontal_flip=True,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.3\n",
        "        #brightness_range=[0.4,1.0]\n",
        "        #zoom_range=[0.15,1.0]\n",
        "    )  # randomly flip images\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history2=model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        steps_per_epoch=len(X_train)/batch_size,\n",
        "                        epochs=epochs, shuffle=True,verbose=1,\n",
        "                        callbacks=callbacks)\n",
        "   \n",
        "    \n",
        "    \n",
        "\n",
        "#validation_freq=5,\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "profondeur: 6\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc5afe80>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc5afe80>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc5afc88>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc5afc88>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc5c77b8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc5c77b8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc58fd30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc58fd30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc573240>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc573240>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc573ba8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc573ba8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc487630>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc487630>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc487780>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc487780>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc482358>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc482358>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc3436a0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc3436a0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc379ba8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc379ba8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc379780>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fe9dc379780>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6da856d8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6da856d8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6da85828>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6da85828>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6da68400>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6da68400>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d9ed470>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d9ed470>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d9ed5c0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d9ed5c0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d9da198>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d9da198>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d88afd0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d88afd0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d88aeb8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d88aeb8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d88af98>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d88af98>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d859588>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "WARNING: AutoGraph could not transform <bound method SoftLIF.call of <__main__.SoftLIF object at 0x7fea6d859588>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: LIVE_VARS_IN\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 32, 32, 3)    12          input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 32, 32, 16)   1216        batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 16)   448         batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_92 (SoftLIF)           (None, 32, 32, 16)   0           conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_93 (SoftLIF)           (None, 32, 32, 16)   0           conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, 32, 32, 16)   0           soft_lif_92[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 32, 32, 16)   0           soft_lif_93[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 32, 32, 16)   64          dropout_92[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 32, 32, 16)   64          dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 32, 32, 32)   0           batch_normalization_85[0][0]     \n",
            "                                                                 batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 32, 32, 32)   25632       concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 32, 32, 32)   4640        batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_95 (SoftLIF)           (None, 32, 32, 32)   0           conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_96 (SoftLIF)           (None, 32, 32, 32)   0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 32, 32, 16)   64          batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_72 (AveragePo (None, 16, 16, 32)   0           soft_lif_95[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_73 (AveragePo (None, 16, 16, 32)   0           soft_lif_96[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_94 (SoftLIF)           (None, 32, 32, 16)   0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_95 (Dropout)            (None, 16, 16, 32)   0           average_pooling2d_72[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, 16, 16, 32)   0           average_pooling2d_73[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, 32, 32, 16)   0           soft_lif_94[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 16, 16, 32)   128         dropout_95[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 16, 16, 32)   128         dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 32, 32, 16)   64          dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 64)   0           batch_normalization_88[0][0]     \n",
            "                                                                 batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 32, 32, 32)   544         batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 16, 16, 64)   102464      concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 16, 16, 64)   18496       batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_97 (SoftLIF)           (None, 32, 32, 32)   0           conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_98 (SoftLIF)           (None, 16, 16, 64)   0           conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_99 (SoftLIF)           (None, 16, 16, 64)   0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_74 (AveragePo (None, 16, 16, 32)   0           soft_lif_97[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_75 (AveragePo (None, 8, 8, 64)     0           soft_lif_98[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_76 (AveragePo (None, 8, 8, 64)     0           soft_lif_99[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_97 (Dropout)            (None, 16, 16, 32)   0           average_pooling2d_74[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, 8, 8, 64)     0           average_pooling2d_75[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_99 (Dropout)            (None, 8, 8, 64)     0           average_pooling2d_76[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 16, 16, 32)   128         dropout_97[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 64)     256         dropout_98[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 64)     256         dropout_99[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 16, 16, 64)   2112        batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 128)    0           batch_normalization_91[0][0]     \n",
            "                                                                 batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_100 (SoftLIF)          (None, 16, 16, 64)   0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 96)     307296      concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 96)     55392       batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_77 (AveragePo (None, 8, 8, 64)     0           soft_lif_100[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_101 (SoftLIF)          (None, 8, 8, 96)     0           conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_102 (SoftLIF)          (None, 8, 8, 96)     0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_100 (Dropout)           (None, 8, 8, 64)     0           average_pooling2d_77[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_78 (AveragePo (None, 4, 4, 96)     0           soft_lif_101[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_79 (AveragePo (None, 4, 4, 96)     0           soft_lif_102[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 64)     256         dropout_100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_101 (Dropout)           (None, 4, 4, 96)     0           average_pooling2d_78[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_102 (Dropout)           (None, 4, 4, 96)     0           average_pooling2d_79[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 96)     6240        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 4, 4, 96)     384         dropout_101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 4, 4, 96)     384         dropout_102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_103 (SoftLIF)          (None, 8, 8, 96)     0           conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 4, 4, 192)    0           batch_normalization_94[0][0]     \n",
            "                                                                 batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_80 (AveragePo (None, 4, 4, 96)     0           soft_lif_103[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 4, 4, 128)    614528      concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 4, 4, 128)    110720      batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 4, 4, 96)     0           average_pooling2d_80[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_104 (SoftLIF)          (None, 4, 4, 128)    0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_105 (SoftLIF)          (None, 4, 4, 128)    0           conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 4, 4, 96)     384         dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_81 (AveragePo (None, 2, 2, 128)    0           soft_lif_104[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_82 (AveragePo (None, 2, 2, 128)    0           soft_lif_105[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 4, 4, 128)    12416       batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 2, 2, 128)    0           average_pooling2d_81[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 2, 2, 128)    0           average_pooling2d_82[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_106 (SoftLIF)          (None, 4, 4, 128)    0           conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 2, 2, 128)    512         dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 2, 2, 128)    512         dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_83 (AveragePo (None, 2, 2, 128)    0           soft_lif_106[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 2, 2, 256)    0           batch_normalization_97[0][0]     \n",
            "                                                                 batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 2, 2, 128)    0           average_pooling2d_83[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 2, 2, 160)    1024160     concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 2, 2, 160)    184480      batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 2, 2, 128)    512         dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_107 (SoftLIF)          (None, 2, 2, 160)    0           conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_108 (SoftLIF)          (None, 2, 2, 160)    0           conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 2, 2, 160)    20640       batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_84 (AveragePo (None, 1, 1, 160)    0           soft_lif_107[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_85 (AveragePo (None, 1, 1, 160)    0           soft_lif_108[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_109 (SoftLIF)          (None, 2, 2, 160)    0           conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 1, 1, 160)    0           average_pooling2d_84[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 1, 1, 160)    0           average_pooling2d_85[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_86 (AveragePo (None, 1, 1, 160)    0           soft_lif_109[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 1, 1, 160)    640         dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 1, 1, 160)    640         dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 1, 1, 160)    0           average_pooling2d_86[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 1, 1, 320)    0           batch_normalization_100[0][0]    \n",
            "                                                                 batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 1, 1, 160)    640         dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 1, 1, 192)    1536192     concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 1, 1, 192)    30912       batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 1, 1, 192)    276672      batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_110 (SoftLIF)          (None, 1, 1, 192)    0           conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_112 (SoftLIF)          (None, 1, 1, 192)    0           conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_111 (SoftLIF)          (None, 1, 1, 192)    0           conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_87 (AveragePo (None, 1, 1, 192)    0           soft_lif_110[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_89 (AveragePo (None, 1, 1, 192)    0           soft_lif_112[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_88 (AveragePo (None, 1, 1, 192)    0           soft_lif_111[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 1, 1, 192)    0           average_pooling2d_87[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 1, 1, 192)    0           average_pooling2d_89[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 1, 1, 192)    0           average_pooling2d_88[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 1, 1, 576)    0           dropout_110[0][0]                \n",
            "                                                                 dropout_112[0][0]                \n",
            "                                                                 dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 576)          0           concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 512)          295424      flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_lif_113 (SoftLIF)          (None, 512)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 512)          0           soft_lif_113[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 10)           5130        dropout_113[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 4,641,782\n",
            "Trainable params: 4,638,800\n",
            "Non-trainable params: 2,982\n",
            "__________________________________________________________________________________________________\n",
            "Using real-time data augmentation.\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 390.625 steps, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "391/390 [==============================] - 70s 180ms/step - loss: 1.9105 - accuracy: 0.2811 - val_loss: 1.5684 - val_accuracy: 0.4112\n",
            "Epoch 2/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 1.6327 - accuracy: 0.3932 - val_loss: 1.4281 - val_accuracy: 0.4662\n",
            "Epoch 3/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 1.5075 - accuracy: 0.4474 - val_loss: 1.3487 - val_accuracy: 0.5022\n",
            "Epoch 4/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 1.4006 - accuracy: 0.4908 - val_loss: 1.3078 - val_accuracy: 0.5331\n",
            "Epoch 5/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 1.3053 - accuracy: 0.5319 - val_loss: 1.0939 - val_accuracy: 0.6013\n",
            "Epoch 6/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 1.2375 - accuracy: 0.5575 - val_loss: 1.1057 - val_accuracy: 0.6069\n",
            "Epoch 7/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 1.1846 - accuracy: 0.5781 - val_loss: 0.9760 - val_accuracy: 0.6470\n",
            "Epoch 8/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 1.1348 - accuracy: 0.6026 - val_loss: 1.0918 - val_accuracy: 0.6266\n",
            "Epoch 9/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 1.0935 - accuracy: 0.6141 - val_loss: 1.0156 - val_accuracy: 0.6542\n",
            "Epoch 10/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 1.0481 - accuracy: 0.6316 - val_loss: 0.9264 - val_accuracy: 0.6748\n",
            "Epoch 11/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 1.0263 - accuracy: 0.6439 - val_loss: 0.8762 - val_accuracy: 0.6944\n",
            "Epoch 12/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.9962 - accuracy: 0.6554 - val_loss: 0.8734 - val_accuracy: 0.6920\n",
            "Epoch 13/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.9710 - accuracy: 0.6640 - val_loss: 0.8322 - val_accuracy: 0.7097\n",
            "Epoch 14/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.9503 - accuracy: 0.6714 - val_loss: 0.8153 - val_accuracy: 0.7166\n",
            "Epoch 15/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.9351 - accuracy: 0.6766 - val_loss: 0.7604 - val_accuracy: 0.7362\n",
            "Epoch 16/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.9097 - accuracy: 0.6874 - val_loss: 0.7798 - val_accuracy: 0.7392\n",
            "Epoch 17/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.8997 - accuracy: 0.6905 - val_loss: 0.7251 - val_accuracy: 0.7507\n",
            "Epoch 18/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.8758 - accuracy: 0.7024 - val_loss: 0.7631 - val_accuracy: 0.7410\n",
            "Epoch 19/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.8692 - accuracy: 0.7025 - val_loss: 0.7419 - val_accuracy: 0.7483\n",
            "Epoch 20/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.8583 - accuracy: 0.7069 - val_loss: 0.7148 - val_accuracy: 0.7616\n",
            "Epoch 21/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.8413 - accuracy: 0.7149 - val_loss: 0.8281 - val_accuracy: 0.7272\n",
            "Epoch 22/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.8320 - accuracy: 0.7162 - val_loss: 0.7449 - val_accuracy: 0.7539\n",
            "Epoch 23/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.8118 - accuracy: 0.7232 - val_loss: 0.6387 - val_accuracy: 0.7848\n",
            "Epoch 24/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.8041 - accuracy: 0.7265 - val_loss: 0.6989 - val_accuracy: 0.7666\n",
            "Epoch 25/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7923 - accuracy: 0.7309 - val_loss: 0.7524 - val_accuracy: 0.7468\n",
            "Epoch 26/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7896 - accuracy: 0.7312 - val_loss: 0.6435 - val_accuracy: 0.7834\n",
            "Epoch 27/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7801 - accuracy: 0.7325 - val_loss: 0.6895 - val_accuracy: 0.7743\n",
            "Epoch 28/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7709 - accuracy: 0.7393 - val_loss: 0.6342 - val_accuracy: 0.7905\n",
            "Epoch 29/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7686 - accuracy: 0.7403 - val_loss: 0.6389 - val_accuracy: 0.7846\n",
            "Epoch 30/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7541 - accuracy: 0.7446 - val_loss: 0.5779 - val_accuracy: 0.8050\n",
            "Epoch 31/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7455 - accuracy: 0.7472 - val_loss: 0.5882 - val_accuracy: 0.8002\n",
            "Epoch 32/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7406 - accuracy: 0.7497 - val_loss: 0.6816 - val_accuracy: 0.7775\n",
            "Epoch 33/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.7356 - accuracy: 0.7509 - val_loss: 0.6043 - val_accuracy: 0.7958\n",
            "Epoch 34/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7229 - accuracy: 0.7540 - val_loss: 0.6304 - val_accuracy: 0.7888\n",
            "Epoch 35/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7235 - accuracy: 0.7542 - val_loss: 0.6020 - val_accuracy: 0.8012\n",
            "Epoch 36/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7170 - accuracy: 0.7556 - val_loss: 0.5510 - val_accuracy: 0.8171\n",
            "Epoch 37/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.7120 - accuracy: 0.7577 - val_loss: 0.5542 - val_accuracy: 0.8166\n",
            "Epoch 38/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.7049 - accuracy: 0.7617 - val_loss: 0.5765 - val_accuracy: 0.8080\n",
            "Epoch 39/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.6973 - accuracy: 0.7634 - val_loss: 0.5554 - val_accuracy: 0.8123\n",
            "Epoch 40/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.6963 - accuracy: 0.7634 - val_loss: 0.6180 - val_accuracy: 0.8033\n",
            "Epoch 41/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6938 - accuracy: 0.7663 - val_loss: 0.5652 - val_accuracy: 0.8067\n",
            "Epoch 42/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6870 - accuracy: 0.7679 - val_loss: 0.5617 - val_accuracy: 0.8125\n",
            "Epoch 43/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.6792 - accuracy: 0.7718 - val_loss: 0.5267 - val_accuracy: 0.8238\n",
            "Epoch 44/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6718 - accuracy: 0.7755 - val_loss: 0.5206 - val_accuracy: 0.8232\n",
            "Epoch 45/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6714 - accuracy: 0.7724 - val_loss: 0.5976 - val_accuracy: 0.8072\n",
            "Epoch 46/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6628 - accuracy: 0.7780 - val_loss: 0.5253 - val_accuracy: 0.8269\n",
            "Epoch 47/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6600 - accuracy: 0.7750 - val_loss: 0.5407 - val_accuracy: 0.8203\n",
            "Epoch 48/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6592 - accuracy: 0.7756 - val_loss: 0.4936 - val_accuracy: 0.8329\n",
            "Epoch 49/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6524 - accuracy: 0.7814 - val_loss: 0.5347 - val_accuracy: 0.8201\n",
            "Epoch 50/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6523 - accuracy: 0.7787 - val_loss: 0.5534 - val_accuracy: 0.8178\n",
            "Epoch 51/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6430 - accuracy: 0.7822 - val_loss: 0.5334 - val_accuracy: 0.8241\n",
            "Epoch 52/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6453 - accuracy: 0.7821 - val_loss: 0.4937 - val_accuracy: 0.8356\n",
            "Epoch 53/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6406 - accuracy: 0.7820 - val_loss: 0.5446 - val_accuracy: 0.8211\n",
            "Epoch 54/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.6396 - accuracy: 0.7833 - val_loss: 0.5619 - val_accuracy: 0.8176\n",
            "Epoch 55/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6365 - accuracy: 0.7852 - val_loss: 0.5557 - val_accuracy: 0.8177\n",
            "Epoch 56/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6316 - accuracy: 0.7878 - val_loss: 0.5081 - val_accuracy: 0.8313\n",
            "Epoch 57/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6250 - accuracy: 0.7890 - val_loss: 0.5562 - val_accuracy: 0.8149\n",
            "Epoch 58/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.6238 - accuracy: 0.7907 - val_loss: 0.5204 - val_accuracy: 0.8245\n",
            "Epoch 59/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6264 - accuracy: 0.7881 - val_loss: 0.5366 - val_accuracy: 0.8217\n",
            "Epoch 60/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6230 - accuracy: 0.7889 - val_loss: 0.5185 - val_accuracy: 0.8264\n",
            "Epoch 61/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.6129 - accuracy: 0.7920 - val_loss: 0.5420 - val_accuracy: 0.8304\n",
            "Epoch 62/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.6218 - accuracy: 0.7897 - val_loss: 0.4434 - val_accuracy: 0.8521\n",
            "Epoch 63/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.6154 - accuracy: 0.7912 - val_loss: 0.5540 - val_accuracy: 0.8227\n",
            "Epoch 64/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.6058 - accuracy: 0.7949 - val_loss: 0.5034 - val_accuracy: 0.8351\n",
            "Epoch 65/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.6027 - accuracy: 0.7962 - val_loss: 0.5315 - val_accuracy: 0.8229\n",
            "Epoch 66/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.6051 - accuracy: 0.7952 - val_loss: 0.4574 - val_accuracy: 0.8473\n",
            "Epoch 67/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5997 - accuracy: 0.7995 - val_loss: 0.5037 - val_accuracy: 0.8347\n",
            "Epoch 68/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5904 - accuracy: 0.7997 - val_loss: 0.4463 - val_accuracy: 0.8516\n",
            "Epoch 69/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5943 - accuracy: 0.7982 - val_loss: 0.4903 - val_accuracy: 0.8384\n",
            "Epoch 70/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5938 - accuracy: 0.7990 - val_loss: 0.4574 - val_accuracy: 0.8442\n",
            "Epoch 71/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5868 - accuracy: 0.7995 - val_loss: 0.4756 - val_accuracy: 0.8445\n",
            "Epoch 72/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5935 - accuracy: 0.7997 - val_loss: 0.4851 - val_accuracy: 0.8388\n",
            "Epoch 73/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5844 - accuracy: 0.8021 - val_loss: 0.4813 - val_accuracy: 0.8430\n",
            "Epoch 74/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5960 - accuracy: 0.7982 - val_loss: 0.5178 - val_accuracy: 0.8300\n",
            "Epoch 75/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5871 - accuracy: 0.8018 - val_loss: 0.4383 - val_accuracy: 0.8551\n",
            "Epoch 76/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5810 - accuracy: 0.8035 - val_loss: 0.5605 - val_accuracy: 0.8229\n",
            "Epoch 77/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5802 - accuracy: 0.8033 - val_loss: 0.4852 - val_accuracy: 0.8403\n",
            "Epoch 78/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5827 - accuracy: 0.8038 - val_loss: 0.4484 - val_accuracy: 0.8504\n",
            "Epoch 79/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5757 - accuracy: 0.8059 - val_loss: 0.4654 - val_accuracy: 0.8452\n",
            "Epoch 80/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5764 - accuracy: 0.8066 - val_loss: 0.5261 - val_accuracy: 0.8278\n",
            "Epoch 81/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5697 - accuracy: 0.8062 - val_loss: 0.4841 - val_accuracy: 0.8442\n",
            "Epoch 82/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5770 - accuracy: 0.8064 - val_loss: 0.4801 - val_accuracy: 0.8416\n",
            "Epoch 83/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5729 - accuracy: 0.8050 - val_loss: 0.4341 - val_accuracy: 0.8571\n",
            "Epoch 84/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5633 - accuracy: 0.8080 - val_loss: 0.4597 - val_accuracy: 0.8501\n",
            "Epoch 85/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5653 - accuracy: 0.8083 - val_loss: 0.4634 - val_accuracy: 0.8473\n",
            "Epoch 86/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5664 - accuracy: 0.8078 - val_loss: 0.4762 - val_accuracy: 0.8463\n",
            "Epoch 87/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5668 - accuracy: 0.8094 - val_loss: 0.4940 - val_accuracy: 0.8358\n",
            "Epoch 88/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5615 - accuracy: 0.8091 - val_loss: 0.4356 - val_accuracy: 0.8543\n",
            "Epoch 89/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5695 - accuracy: 0.8089 - val_loss: 0.4889 - val_accuracy: 0.8403\n",
            "Epoch 90/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5618 - accuracy: 0.8123 - val_loss: 0.4355 - val_accuracy: 0.8577\n",
            "Epoch 91/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5525 - accuracy: 0.8122 - val_loss: 0.4337 - val_accuracy: 0.8581\n",
            "Epoch 92/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5543 - accuracy: 0.8124 - val_loss: 0.4129 - val_accuracy: 0.8641\n",
            "Epoch 93/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5497 - accuracy: 0.8158 - val_loss: 0.4790 - val_accuracy: 0.8443\n",
            "Epoch 94/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5508 - accuracy: 0.8142 - val_loss: 0.4870 - val_accuracy: 0.8431\n",
            "Epoch 95/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5491 - accuracy: 0.8146 - val_loss: 0.4253 - val_accuracy: 0.8588\n",
            "Epoch 96/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5589 - accuracy: 0.8093 - val_loss: 0.4796 - val_accuracy: 0.8463\n",
            "Epoch 97/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5533 - accuracy: 0.8152 - val_loss: 0.4668 - val_accuracy: 0.8468\n",
            "Epoch 98/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5499 - accuracy: 0.8139 - val_loss: 0.4341 - val_accuracy: 0.8529\n",
            "Epoch 99/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5502 - accuracy: 0.8132 - val_loss: 0.4505 - val_accuracy: 0.8505\n",
            "Epoch 100/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5449 - accuracy: 0.8153 - val_loss: 0.4324 - val_accuracy: 0.8586\n",
            "Epoch 101/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5422 - accuracy: 0.8182 - val_loss: 0.4583 - val_accuracy: 0.8460\n",
            "Epoch 102/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5411 - accuracy: 0.8194 - val_loss: 0.4612 - val_accuracy: 0.8472\n",
            "Epoch 103/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5480 - accuracy: 0.8151 - val_loss: 0.5062 - val_accuracy: 0.8318\n",
            "Epoch 104/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5410 - accuracy: 0.8172 - val_loss: 0.4599 - val_accuracy: 0.8484\n",
            "Epoch 105/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5322 - accuracy: 0.8206 - val_loss: 0.4101 - val_accuracy: 0.8637\n",
            "Epoch 106/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5408 - accuracy: 0.8172 - val_loss: 0.4648 - val_accuracy: 0.8520\n",
            "Epoch 107/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5324 - accuracy: 0.8208 - val_loss: 0.4009 - val_accuracy: 0.8659\n",
            "Epoch 108/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5341 - accuracy: 0.8191 - val_loss: 0.4443 - val_accuracy: 0.8566\n",
            "Epoch 109/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5352 - accuracy: 0.8195 - val_loss: 0.4749 - val_accuracy: 0.8496\n",
            "Epoch 110/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5384 - accuracy: 0.8203 - val_loss: 0.4653 - val_accuracy: 0.8516\n",
            "Epoch 111/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5326 - accuracy: 0.8203 - val_loss: 0.4367 - val_accuracy: 0.8588\n",
            "Epoch 112/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5376 - accuracy: 0.8198 - val_loss: 0.4171 - val_accuracy: 0.8597\n",
            "Epoch 113/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5293 - accuracy: 0.8218 - val_loss: 0.4578 - val_accuracy: 0.8497\n",
            "Epoch 114/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5287 - accuracy: 0.8192 - val_loss: 0.4205 - val_accuracy: 0.8610\n",
            "Epoch 115/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5320 - accuracy: 0.8210 - val_loss: 0.4631 - val_accuracy: 0.8506\n",
            "Epoch 116/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5213 - accuracy: 0.8248 - val_loss: 0.4101 - val_accuracy: 0.8625\n",
            "Epoch 117/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5193 - accuracy: 0.8252 - val_loss: 0.4176 - val_accuracy: 0.8615\n",
            "Epoch 118/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5220 - accuracy: 0.8233 - val_loss: 0.4147 - val_accuracy: 0.8629\n",
            "Epoch 119/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5275 - accuracy: 0.8229 - val_loss: 0.4744 - val_accuracy: 0.8466\n",
            "Epoch 120/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5248 - accuracy: 0.8245 - val_loss: 0.4290 - val_accuracy: 0.8576\n",
            "Epoch 121/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5173 - accuracy: 0.8258 - val_loss: 0.4311 - val_accuracy: 0.8603\n",
            "Epoch 122/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5152 - accuracy: 0.8257 - val_loss: 0.4460 - val_accuracy: 0.8534\n",
            "Epoch 123/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5256 - accuracy: 0.8227 - val_loss: 0.4008 - val_accuracy: 0.8654\n",
            "Epoch 124/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5222 - accuracy: 0.8223 - val_loss: 0.4507 - val_accuracy: 0.8583\n",
            "Epoch 125/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5219 - accuracy: 0.8241 - val_loss: 0.4501 - val_accuracy: 0.8526\n",
            "Epoch 126/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.5186 - accuracy: 0.8247 - val_loss: 0.4235 - val_accuracy: 0.8605\n",
            "Epoch 127/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5217 - accuracy: 0.8262 - val_loss: 0.4359 - val_accuracy: 0.8545\n",
            "Epoch 128/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5150 - accuracy: 0.8272 - val_loss: 0.3961 - val_accuracy: 0.8714\n",
            "Epoch 129/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5166 - accuracy: 0.8268 - val_loss: 0.4391 - val_accuracy: 0.8575\n",
            "Epoch 130/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5200 - accuracy: 0.8243 - val_loss: 0.4352 - val_accuracy: 0.8530\n",
            "Epoch 131/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5114 - accuracy: 0.8265 - val_loss: 0.4179 - val_accuracy: 0.8618\n",
            "Epoch 132/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5097 - accuracy: 0.8272 - val_loss: 0.4447 - val_accuracy: 0.8550\n",
            "Epoch 133/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5131 - accuracy: 0.8252 - val_loss: 0.4056 - val_accuracy: 0.8608\n",
            "Epoch 134/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5083 - accuracy: 0.8267 - val_loss: 0.4469 - val_accuracy: 0.8506\n",
            "Epoch 135/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5140 - accuracy: 0.8248 - val_loss: 0.4154 - val_accuracy: 0.8671\n",
            "Epoch 136/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5101 - accuracy: 0.8261 - val_loss: 0.3944 - val_accuracy: 0.8672\n",
            "Epoch 137/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5163 - accuracy: 0.8272 - val_loss: 0.4262 - val_accuracy: 0.8569\n",
            "Epoch 138/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5042 - accuracy: 0.8313 - val_loss: 0.4012 - val_accuracy: 0.8685\n",
            "Epoch 139/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5045 - accuracy: 0.8303 - val_loss: 0.4101 - val_accuracy: 0.8662\n",
            "Epoch 140/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5059 - accuracy: 0.8281 - val_loss: 0.4276 - val_accuracy: 0.8598\n",
            "Epoch 141/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5088 - accuracy: 0.8293 - val_loss: 0.4138 - val_accuracy: 0.8610\n",
            "Epoch 142/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5043 - accuracy: 0.8309 - val_loss: 0.4130 - val_accuracy: 0.8635\n",
            "Epoch 143/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5051 - accuracy: 0.8299 - val_loss: 0.4005 - val_accuracy: 0.8706\n",
            "Epoch 144/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.5006 - accuracy: 0.8326 - val_loss: 0.4102 - val_accuracy: 0.8634\n",
            "Epoch 145/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.4991 - accuracy: 0.8337 - val_loss: 0.4198 - val_accuracy: 0.8628\n",
            "Epoch 146/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.4976 - accuracy: 0.8299 - val_loss: 0.4173 - val_accuracy: 0.8606\n",
            "Epoch 147/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.4986 - accuracy: 0.8302 - val_loss: 0.4161 - val_accuracy: 0.8623\n",
            "Epoch 148/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.5037 - accuracy: 0.8294 - val_loss: 0.3968 - val_accuracy: 0.8691\n",
            "Epoch 149/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.4974 - accuracy: 0.8316 - val_loss: 0.3889 - val_accuracy: 0.8712\n",
            "Epoch 150/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4973 - accuracy: 0.8332 - val_loss: 0.4271 - val_accuracy: 0.8637\n",
            "Epoch 151/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4979 - accuracy: 0.8306 - val_loss: 0.3916 - val_accuracy: 0.8739\n",
            "Epoch 152/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4951 - accuracy: 0.8339 - val_loss: 0.4204 - val_accuracy: 0.8656\n",
            "Epoch 153/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.4955 - accuracy: 0.8338 - val_loss: 0.4024 - val_accuracy: 0.8668\n",
            "Epoch 154/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4983 - accuracy: 0.8322 - val_loss: 0.4034 - val_accuracy: 0.8678\n",
            "Epoch 155/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4985 - accuracy: 0.8329 - val_loss: 0.4145 - val_accuracy: 0.8704\n",
            "Epoch 156/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.4927 - accuracy: 0.8338 - val_loss: 0.4328 - val_accuracy: 0.8622\n",
            "Epoch 157/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.5011 - accuracy: 0.8332 - val_loss: 0.4316 - val_accuracy: 0.8598\n",
            "Epoch 158/200\n",
            "391/390 [==============================] - 65s 166ms/step - loss: 0.4962 - accuracy: 0.8331 - val_loss: 0.4383 - val_accuracy: 0.8579\n",
            "Epoch 159/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4943 - accuracy: 0.8336 - val_loss: 0.3968 - val_accuracy: 0.8686\n",
            "Epoch 160/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4978 - accuracy: 0.8319 - val_loss: 0.4103 - val_accuracy: 0.8682\n",
            "Epoch 161/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.5004 - accuracy: 0.8315 - val_loss: 0.4057 - val_accuracy: 0.8653\n",
            "Epoch 162/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4845 - accuracy: 0.8373 - val_loss: 0.4132 - val_accuracy: 0.8673\n",
            "Epoch 163/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4954 - accuracy: 0.8326 - val_loss: 0.4514 - val_accuracy: 0.8551\n",
            "Epoch 164/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.4928 - accuracy: 0.8351 - val_loss: 0.3962 - val_accuracy: 0.8708\n",
            "Epoch 165/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4922 - accuracy: 0.8346 - val_loss: 0.4068 - val_accuracy: 0.8678\n",
            "Epoch 166/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4934 - accuracy: 0.8340 - val_loss: 0.4157 - val_accuracy: 0.8634\n",
            "Epoch 167/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4919 - accuracy: 0.8329 - val_loss: 0.4253 - val_accuracy: 0.8649\n",
            "Epoch 168/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4856 - accuracy: 0.8355 - val_loss: 0.3795 - val_accuracy: 0.8737\n",
            "Epoch 169/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4888 - accuracy: 0.8347 - val_loss: 0.3924 - val_accuracy: 0.8710\n",
            "Epoch 170/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4851 - accuracy: 0.8356 - val_loss: 0.4095 - val_accuracy: 0.8687\n",
            "Epoch 171/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4827 - accuracy: 0.8372 - val_loss: 0.3799 - val_accuracy: 0.8764\n",
            "Epoch 172/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.4869 - accuracy: 0.8348 - val_loss: 0.4101 - val_accuracy: 0.8683\n",
            "Epoch 173/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4809 - accuracy: 0.8367 - val_loss: 0.4216 - val_accuracy: 0.8644\n",
            "Epoch 174/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4871 - accuracy: 0.8357 - val_loss: 0.4037 - val_accuracy: 0.8703\n",
            "Epoch 175/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4830 - accuracy: 0.8369 - val_loss: 0.3666 - val_accuracy: 0.8815\n",
            "Epoch 176/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4828 - accuracy: 0.8369 - val_loss: 0.3748 - val_accuracy: 0.8751\n",
            "Epoch 177/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.4863 - accuracy: 0.8343 - val_loss: 0.4178 - val_accuracy: 0.8683\n",
            "Epoch 178/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.4861 - accuracy: 0.8366 - val_loss: 0.3916 - val_accuracy: 0.8766\n",
            "Epoch 179/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4791 - accuracy: 0.8392 - val_loss: 0.3802 - val_accuracy: 0.8736\n",
            "Epoch 180/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.4763 - accuracy: 0.8384 - val_loss: 0.3843 - val_accuracy: 0.8741\n",
            "Epoch 181/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4831 - accuracy: 0.8350 - val_loss: 0.4161 - val_accuracy: 0.8660\n",
            "Epoch 182/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4838 - accuracy: 0.8390 - val_loss: 0.3787 - val_accuracy: 0.8768\n",
            "Epoch 183/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4792 - accuracy: 0.8373 - val_loss: 0.3912 - val_accuracy: 0.8682\n",
            "Epoch 184/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.4816 - accuracy: 0.8369 - val_loss: 0.4590 - val_accuracy: 0.8515\n",
            "Epoch 185/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4773 - accuracy: 0.8378 - val_loss: 0.4124 - val_accuracy: 0.8684\n",
            "Epoch 186/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.4777 - accuracy: 0.8366 - val_loss: 0.4309 - val_accuracy: 0.8653\n",
            "Epoch 187/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4754 - accuracy: 0.8375 - val_loss: 0.4112 - val_accuracy: 0.8695\n",
            "Epoch 188/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4772 - accuracy: 0.8373 - val_loss: 0.3842 - val_accuracy: 0.8799\n",
            "Epoch 189/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4858 - accuracy: 0.8370 - val_loss: 0.3870 - val_accuracy: 0.8737\n",
            "Epoch 190/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4742 - accuracy: 0.8397 - val_loss: 0.3949 - val_accuracy: 0.8745\n",
            "Epoch 191/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4774 - accuracy: 0.8389 - val_loss: 0.4202 - val_accuracy: 0.8646\n",
            "Epoch 192/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4736 - accuracy: 0.8397 - val_loss: 0.4070 - val_accuracy: 0.8707\n",
            "Epoch 193/200\n",
            "391/390 [==============================] - 64s 164ms/step - loss: 0.4766 - accuracy: 0.8366 - val_loss: 0.4004 - val_accuracy: 0.8725\n",
            "Epoch 194/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4772 - accuracy: 0.8388 - val_loss: 0.3912 - val_accuracy: 0.8749\n",
            "Epoch 195/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4694 - accuracy: 0.8406 - val_loss: 0.4060 - val_accuracy: 0.8644\n",
            "Epoch 196/200\n",
            "391/390 [==============================] - 65s 165ms/step - loss: 0.4764 - accuracy: 0.8386 - val_loss: 0.4089 - val_accuracy: 0.8669\n",
            "Epoch 197/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4704 - accuracy: 0.8409 - val_loss: 0.4104 - val_accuracy: 0.8669\n",
            "Epoch 198/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4709 - accuracy: 0.8407 - val_loss: 0.4043 - val_accuracy: 0.8741\n",
            "Epoch 199/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4711 - accuracy: 0.8416 - val_loss: 0.3909 - val_accuracy: 0.8691\n",
            "Epoch 200/200\n",
            "391/390 [==============================] - 64s 165ms/step - loss: 0.4750 - accuracy: 0.8416 - val_loss: 0.4111 - val_accuracy: 0.8697\n",
            "Test score: 0.4111352040410042\n",
            "Test accuracy: 0.8697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdzVZe3-cId4"
      },
      "source": [
        "# **VIZULISATION **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9uJJJFqcG8M"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "def n_(node, output_format_):\n",
        "    node_name = str(node.name)\n",
        "    if output_format_ == 'simple':\n",
        "        if '/' in node_name:\n",
        "            return node_name.split('/')[0]\n",
        "        elif ':' in node_name:\n",
        "            return node_name.split(':')[0]\n",
        "        else:\n",
        "            return node_name\n",
        "    return node_name\n",
        "\n",
        "\n",
        "def _evaluate(model: Model, nodes_to_evaluate, x, y=None, auto_compile=False):\n",
        "    if not model._is_compiled:\n",
        "        if model.name in ['vgg16', 'vgg19', 'inception_v3', 'inception_resnet_v2', 'mobilenet_v2', 'mobilenetv2']:\n",
        "            print('Transfer learning detected. Model will be compiled with (\"categorical_crossentropy\", \"adam\").')\n",
        "            print('If you want to change the default behaviour, then do in python:')\n",
        "            print('model.name = \"\"')\n",
        "            print('Then compile your model with whatever loss you want: https://keras.io/models/model/#compile.')\n",
        "            print('If you want to get rid of this message, add this line before calling keract:')\n",
        "            print('model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")')\n",
        "            model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "        else:\n",
        "            if auto_compile:\n",
        "                model.compile(loss='mse', optimizer='adam')\n",
        "            else:\n",
        "                print('Please compile your model first! https://keras.io/models/model/#compile.')\n",
        "                print('If you only care about the activations (outputs of the layers), '\n",
        "                      'then just compile your model like that:')\n",
        "                print('model.compile(loss=\"mse\", optimizer=\"adam\")')\n",
        "                raise Exception('Compilation of the model required.')\n",
        "\n",
        "    def eval_fn(k_inputs):\n",
        "        return K.function(k_inputs, nodes_to_evaluate)(model._standardize_user_data(x, y))\n",
        "\n",
        "    try:\n",
        "        return eval_fn(model._feed_inputs + model._feed_targets + model._feed_sample_weights)\n",
        "    except Exception:\n",
        "        return eval_fn(model._feed_inputs)\n",
        "\n",
        "\n",
        "def get_gradients_of_trainable_weights(model, x, y):\n",
        "    \"\"\"\n",
        "    Get the gradients of trainable_weights for the kernel and the bias nodes for all filters in each layer.\n",
        "    Trainable_weights gradients are averaged over the minibatch.\n",
        "    :param model: keras compiled model or one of ['vgg16', 'vgg19', 'inception_v3', 'inception_resnet_v2',\n",
        "    'mobilenet_v2', 'mobilenetv2']\n",
        "    :param x: inputs for which gradients are sought (averaged over all inputs if batch_size > 1)\n",
        "    :param y: outputs for which gradients are sought\n",
        "    :return: dict mapping layers to corresponding gradients (filter_h, filter_w, in_channels, out_channels)\n",
        "    \"\"\"\n",
        "    nodes = model.trainable_weights\n",
        "    nodes_names = [w.name for w in nodes]\n",
        "    return _get_gradients(model, x, y, nodes, nodes_names)\n",
        "\n",
        "\n",
        "def get_gradients_of_activations(model, x, y, layer_name=None, output_format='simple'):\n",
        "    \"\"\"\n",
        "    Get gradients of the outputs of the activation functions, regarding the loss.\n",
        "    Intuitively, it shows how your activation maps change over a tiny modification of the loss.\n",
        "    :param model: keras compiled model or one of ['vgg16', 'vgg19', 'inception_v3', 'inception_resnet_v2',\n",
        "    'mobilenet_v2', 'mobilenetv2'].\n",
        "    :param x: Model input (Numpy array). In the case of multi-inputs, x should be of type List.\n",
        "    :param y: Model target (Numpy array). In the case of multi-inputs, y should be of type List.\n",
        "    :param layer_name: (optional) Name of a layer for which activations should be returned only. It is useful in\n",
        "    very big networks when it is computationally expensive to evaluate all the layers/nodes.\n",
        "    :param output_format: Change the output dictionary key of the function.\n",
        "    - 'simple': output key will match the names of the Keras layers. For example Dense(1, name='d1') will\n",
        "    return {'d1': ...}.\n",
        "    - 'full': output key will match the full name of the output layer name. In the example above, it will\n",
        "    return {'d1/BiasAdd:0': ...}.\n",
        "    - 'numbered': output key will be an index range, based on the order of definition of each layer within the model.\n",
        "    :return: Dict {layer_name (specified by output_format) -> activation of the layer output/node (Numpy array)}.\n",
        "    \"\"\"\n",
        "    nodes = [layer.output for layer in model.layers if layer.name == layer_name or layer_name is None]\n",
        "    return _get_gradients(model, x, y, nodes, output_format)\n",
        "\n",
        "\n",
        "def _get_gradients(model, x, y, nodes, output_format):\n",
        "    if model.optimizer is None:\n",
        "        raise Exception('Please compile the model first. The loss function is required to compute the gradients.')\n",
        "    try:\n",
        "        grads = model.optimizer.get_gradients(model.total_loss, nodes)\n",
        "    except ValueError as e:\n",
        "        if 'differentiable' in str(e):\n",
        "            # Probably one of the gradients operations is not differentiable...\n",
        "            grads = []\n",
        "            differentiable_nodes = []\n",
        "            for n in nodes:\n",
        "                try:\n",
        "                    grads.extend(model.optimizer.get_gradients(model.total_loss, n))\n",
        "                    differentiable_nodes.append(n)\n",
        "                except ValueError:\n",
        "                    pass\n",
        "            nodes = differentiable_nodes\n",
        "        else:\n",
        "            raise e\n",
        "\n",
        "    gradients_values = _evaluate(model, grads, x, y)\n",
        "    nodes_names = [n_(n, output_format) for n in nodes]\n",
        "    if len(set(nodes_names)) != len(nodes):  # collision detected.\n",
        "        nodes_names = [n_(n, 'full') for n in nodes]\n",
        "    return OrderedDict(zip(nodes_names, gradients_values))\n",
        "\n",
        "\n",
        "def get_activations(model, x, layer_name=None, nodes_to_evaluate=None,\n",
        "                    output_format='simple', auto_compile=True):\n",
        "    \"\"\"\n",
        "    Fetch activations (nodes/layers outputs as Numpy arrays) for a Keras model and an input X.\n",
        "    By default, all the activations for all the layers are returned.\n",
        "    :param model: Keras compiled model or one of ['vgg16', 'vgg19', 'inception_v3', 'inception_resnet_v2',\n",
        "    'mobilenet_v2', 'mobilenetv2', ...].\n",
        "    :param x: Model input (Numpy array). In the case of multi-inputs, x should be of type List.\n",
        "    :param layer_name: (optional) Name of a layer for which activations should be returned only. It is useful in\n",
        "    very big networks when it is computationally expensive to evaluate all the layers/nodes.\n",
        "    :param nodes_to_evaluate: (optional) List of Keras nodes to be evaluated. Useful when the nodes are not\n",
        "    in model.layers.\n",
        "    :param output_format: Change the output dictionary key of the function.\n",
        "    - 'simple': output key will match the names of the Keras layers. For example Dense(1, name='d1') will\n",
        "    return {'d1': ...}.\n",
        "    - 'full': output key will match the full name of the output layer name. In the example above, it will\n",
        "    return {'d1/BiasAdd:0': ...}.\n",
        "    - 'numbered': output key will be an index range, based on the order of definition of each layer within the model.\n",
        "    :param auto_compile: If set to True, will auto-compile the model if needed.\n",
        "    :return: Dict {layer_name (specified by output_format) -> activation of the layer output/node (Numpy array)}.\n",
        "    \"\"\"\n",
        "    if nodes_to_evaluate is None:\n",
        "        nodes = [layer.output for layer in model.layers if layer.name == layer_name or layer_name is None]\n",
        "    else:\n",
        "        if layer_name is not None:\n",
        "            raise ValueError('Do not specify a [layer_name] with [nodes_to_evaluate]. It will not be used.')\n",
        "        nodes = nodes_to_evaluate\n",
        "\n",
        "    if len(nodes) == 0:\n",
        "        if layer_name is not None:\n",
        "            network_layers = ', '.join([layer.name for layer in model.layers])\n",
        "            raise KeyError('Could not find a layer with name: [{}]. '\n",
        "                           'Network layers are [{}]'.format(layer_name, network_layers))\n",
        "        else:\n",
        "            raise ValueError('Nodes list is empty. Or maybe the model is empty.')\n",
        "\n",
        "    # The placeholders are processed later (Inputs node in Keras). Due to a small bug in tensorflow.\n",
        "    input_layer_outputs, layer_outputs = [], []\n",
        "    [input_layer_outputs.append(node) if 'input_' in node.name else layer_outputs.append(node) for node in nodes]\n",
        "    activations = _evaluate(model, layer_outputs, x, y=None, auto_compile=auto_compile)\n",
        "\n",
        "    def craft_output(output_format_):\n",
        "        activations_dict = OrderedDict(zip([n_(output, output_format_) for output in layer_outputs], activations))\n",
        "        activations_inputs_dict = OrderedDict(zip([n_(output, output_format_) for output in input_layer_outputs], x))\n",
        "        result_ = activations_inputs_dict.copy()\n",
        "        result_.update(activations_dict)\n",
        "        if output_format_ == 'numbered':\n",
        "            result_ = OrderedDict([(i, v) for i, (k, v) in enumerate(result_.items())])\n",
        "        return result_\n",
        "\n",
        "    result = craft_output(output_format)\n",
        "    if nodes_to_evaluate is not None and len(result) != len(nodes_to_evaluate):\n",
        "        result = craft_output(output_format_='full')  # collision detected in the keys.\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def display_activations(activations, cmap=None, save=False, directory='.', data_format='channels_last'):\n",
        "    \"\"\"\n",
        "    Plot the activations for each layer using matplotlib\n",
        "    :param activations: dict - mapping layers to corresponding activations (1, output_h, output_w, num_filters)\n",
        "    :param cmap: string - a valid matplotlib colormap to be used\n",
        "    :param save: bool - if the plot should be saved\n",
        "    :param directory: string - where to store the activations (if save is True)\n",
        "    :param data_format: string - one of \"channels_last\" (default) or \"channels_first\".\n",
        "    The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with\n",
        "    shape (batch, steps, channels) (default format for temporal data in Keras) while \"channels_first\"\n",
        "    corresponds to inputs with shape (batch, channels, steps).\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import math\n",
        "    index = 0\n",
        "    for layer_name, acts in activations.items():\n",
        "        print(layer_name, acts.shape, end=' ')\n",
        "        if acts.shape[0] != 1:\n",
        "            print('-> Skipped. First dimension is not 1.')\n",
        "            continue\n",
        "\n",
        "        print('')\n",
        "        # channel first\n",
        "        if data_format == 'channels_last':\n",
        "            c = -1\n",
        "        elif data_format == 'channels_first':\n",
        "            c = 1\n",
        "        else:\n",
        "            raise Exception('Unknown data_format.')\n",
        "\n",
        "        nrows = int(math.sqrt(acts.shape[c]) - 0.001) + 1  # best square fit for the given number\n",
        "        ncols = int(math.ceil(acts.shape[c] / nrows))\n",
        "        hmap = None\n",
        "        if len(acts.shape) <= 2:\n",
        "            \"\"\"\n",
        "            print('-> Skipped. 2D Activations.')\n",
        "            continue\n",
        "            \"\"\"\n",
        "            # no channel\n",
        "            fig, axes = plt.subplots(1, 1, squeeze=False, figsize=(24, 24))\n",
        "            img = acts[0, :]\n",
        "            hmap = axes.flat[0].imshow([img], cmap=cmap)\n",
        "            axes.flat[0].axis('off')\n",
        "        else:\n",
        "            fig, axes = plt.subplots(nrows, ncols, squeeze=False, figsize=(24, 24))\n",
        "            for i in range(nrows * ncols):\n",
        "                if i < acts.shape[c]:\n",
        "                    if len(acts.shape) == 3:\n",
        "                        if data_format == 'channels_last':\n",
        "                            img = acts[0, :, i]\n",
        "                        elif data_format == 'channels_first':\n",
        "                            img = acts[0, i, :]\n",
        "                        else:\n",
        "                            raise Exception('Unknown data_format.')\n",
        "                        hmap = axes.flat[i].imshow([img], cmap=cmap)\n",
        "                    elif len(acts.shape) == 4:\n",
        "                        if data_format == 'channels_last':\n",
        "                            img = acts[0, :, :, i]\n",
        "                        elif data_format == 'channels_first':\n",
        "                            img = acts[0, i, :, :]\n",
        "                        else:\n",
        "                            raise Exception('Unknown data_format.')\n",
        "                        hmap = axes.flat[i].imshow(img, cmap=cmap)\n",
        "                axes.flat[i].axis('off')\n",
        "        fig.suptitle(layer_name)\n",
        "        fig.subplots_adjust(right=0.8)\n",
        "        cbar = fig.add_axes([0.85, 0.15, 0.03, 0.7])\n",
        "        fig.colorbar(hmap, cax=cbar)\n",
        "        if save:\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            output_filename = os.path.join(directory, '{0}_{1}.png'.format(index, layer_name.split('/')[0]))\n",
        "            plt.savefig(output_filename, bbox_inches='tight')\n",
        "        else:\n",
        "            plt.show()\n",
        "        # pyplot figures require manual closing\n",
        "        index += 1\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "def display_heatmaps(activations, input_image, directory='.', save=False, fix=True):\n",
        "    \"\"\"\n",
        "    Plot heatmaps of activations for all filters overlayed on the input image for each layer\n",
        "    :param activations: dict mapping layers to corresponding activations with the shape\n",
        "    (1, output height, output width, number of filters)\n",
        "    :param input_image: numpy array, input image for the overlay\n",
        "    :param save: bool, if the plot should be saved\n",
        "    :param fix: bool, if automated checks and fixes for incorrect images should be run\n",
        "    :param directory: string - where to store the activations (if save is True)\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    from PIL import Image\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    import numpy as np\n",
        "    import math\n",
        "\n",
        "    data_format = K.image_data_format()\n",
        "    if fix:\n",
        "        # fixes common errors made when passing the image\n",
        "        # I recommend the use of keras' load_img function passed to np.array to ensure\n",
        "        # images are loaded in in the correct format\n",
        "        # removes the batch size from the shape\n",
        "        if len(input_image.shape) == 4:\n",
        "            input_image = input_image.reshape(input_image.shape[1], input_image.shape[2], input_image.shape[3])\n",
        "        # removes channels from the shape of grayscale images\n",
        "        if len(input_image.shape) == 3 and input_image.shape[2] == 1:\n",
        "            input_image = input_image.reshape(input_image.shape[0], input_image.shape[1])\n",
        "\n",
        "    index = 0\n",
        "    for layer_name, acts in activations.items():\n",
        "        print(layer_name, acts.shape, end=' ')\n",
        "        if acts.shape[0] != 1:\n",
        "            print('-> Skipped. First dimension is not 1.')\n",
        "            continue\n",
        "        if len(acts.shape) <= 2:\n",
        "            print('-> Skipped. 2D Activations.')\n",
        "            continue\n",
        "        print('')\n",
        "        nrows = int(math.sqrt(acts.shape[-1]) - 0.001) + 1  # best square fit for the given number\n",
        "        ncols = int(math.ceil(acts.shape[-1] / nrows))\n",
        "        fig, axes = plt.subplots(nrows, ncols, figsize=(12, 12))\n",
        "        fig.suptitle(layer_name)\n",
        "\n",
        "        # computes values required to scale the activations (which will form our heat map) to be in range 0-1\n",
        "        scaler = MinMaxScaler()\n",
        "        # reshapes to be 2D with an automaticly calculated first dimension and second\n",
        "        # dimension of 1 in order to keep scikitlearn happy\n",
        "        scaler.fit(acts.reshape(-1, 1))\n",
        "\n",
        "        # loops over each filter/neuron\n",
        "        for i in range(nrows * ncols):\n",
        "            if i < acts.shape[-1]:\n",
        "                if len(acts.shape) == 3:\n",
        "                    # gets the activation of the ith layer\n",
        "                    if data_format == 'channels_last':\n",
        "                        img = acts[0, :, i]\n",
        "                    elif data_format == 'channels_first':\n",
        "                        img = acts[0, i, :]\n",
        "                    else:\n",
        "                        raise Exception('Unknown data_format.')\n",
        "                elif len(acts.shape) == 4:\n",
        "                    if data_format == 'channels_last':\n",
        "                        img = acts[0, :, :, i]\n",
        "                    elif data_format == 'channels_first':\n",
        "                        img = acts[0, i, :, :]\n",
        "                    else:\n",
        "                        raise Exception('Unknown data_format.')\n",
        "                else:\n",
        "                    raise Exception('Expect a tensor of 3 or 4 dimensions.')\n",
        "\n",
        "                # scales the activation (which will form our heat map) to be in range 0-1 using\n",
        "                # the previously calculated statistics\n",
        "                if len(img.shape) == 1:\n",
        "                    img = scaler.transform(img.reshape(-1, 1))\n",
        "                else:\n",
        "                    img = scaler.transform(img)\n",
        "                # print(img.shape)\n",
        "                img = Image.fromarray(img)\n",
        "                # resizes the activation to be same dimensions of input_image\n",
        "                img = img.resize((input_image.shape[0], input_image.shape[1]), Image.LANCZOS)\n",
        "                img = np.array(img)\n",
        "                axes.flat[i].imshow(input_image / 255.0)\n",
        "                # overlay the activation at 70% transparency  onto the image with a heatmap colour scheme\n",
        "                # Lowest activations are dark, highest are dark red, mid are yellow\n",
        "                axes.flat[i].imshow(img, alpha=0.3, cmap='jet', interpolation='bilinear')\n",
        "            axes.flat[i].axis('off')\n",
        "        if save:\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            output_filename = os.path.join(directory, '{0}_{1}.png'.format(index, layer_name.split('/')[0]))\n",
        "            plt.savefig(output_filename, bbox_inches='tight')\n",
        "        else:\n",
        "            plt.show()\n",
        "        index += 1\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "def display_gradients_of_trainable_weights(gradients, directory='.', save=False):\n",
        "    \"\"\"\n",
        "    Plot in_channels by out_channels grid of grad heatmaps each of dimensions (filter_h, filter_w)\n",
        "    :param gradients: dict mapping layers to corresponding gradients (filter_h, filter_w, in_channels, out_channels)\n",
        "    :param save: bool- if the plot should be saved\n",
        "    :param directory: string - where to store the activations (if save is True)\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    index = 0\n",
        "    for layer_name, grads in gradients.items():\n",
        "        if len(grads.shape) != 4:\n",
        "            print(layer_name, \": Expected dimensions (filter_h, filter_w, in_channels, out_channels). Got \",\n",
        "                  grads.shape)\n",
        "            continue\n",
        "        print(layer_name, grads.shape)\n",
        "        nrows = grads.shape[-1]\n",
        "        ncols = grads.shape[-2]\n",
        "        fig, axes = plt.subplots(nrows, ncols, figsize=(12, 12))\n",
        "        fig.suptitle(layer_name)\n",
        "        hmap = None\n",
        "        for i in range(nrows):\n",
        "            for j in range(ncols):\n",
        "                g = grads[:, :, j, i]\n",
        "                hmap = axes[i, j].imshow(g, aspect='auto')  # May cause distortion in case of in_out channel difference\n",
        "                axes[i, j].axis('off')\n",
        "        fig.subplots_adjust(right=0.8, wspace=0.02, hspace=0.3)\n",
        "        cbar = fig.add_axes([0.85, 0.15, 0.03, 0.7])\n",
        "        fig.colorbar(hmap, cax=cbar)\n",
        "        if save:\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            output_filename = os.path.join(directory, '{0}_{1}.png'.format(index, layer_name.split('/')[0]))\n",
        "            plt.savefig(output_filename, bbox_inches='tight')\n",
        "        else:\n",
        "            plt.show()\n",
        "        index += 1\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "def persist_to_json_file(activations, filename):\n",
        "    \"\"\"\n",
        "    Persist the activations to the disk\n",
        "    :param activations: activations (dict mapping layers)\n",
        "    :param filename: output filename (JSON format)\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    with open(filename, 'w') as w:\n",
        "        json.dump(fp=w, obj=OrderedDict({k: v.tolist() for k, v in activations.items()}), indent=2, sort_keys=False)\n",
        "\n",
        "\n",
        "def load_activations_from_json_file(filename):\n",
        "    \"\"\"\n",
        "    Read the activations from the disk\n",
        "    :param filename: filename to read the activations from (JSON format)\n",
        "    :return: activations (dict mapping layers)\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    with open(filename, 'r') as r:\n",
        "        d = json.load(r, object_pairs_hook=OrderedDict)\n",
        "        activations = OrderedDict({k: np.array(v) for k, v in d.items()})\n",
        "        return activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsCZGxDHjmWA"
      },
      "source": [
        "# **Architecture ZCNN Image score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gdQ2DngHEPi1",
        "outputId": "609eeef5-8917-4baf-cae9-e64e5c8dab13"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "#from keras.optimizers import Nadam,Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import (Activation, Conv2D,GlobalAveragePooling2D, Dense, Dropout, Flatten,AvgPool2D,MaxPooling2D,LeakyReLU,Input,Concatenate,Subtract)\n",
        "from tensorflow.python.keras.layers.noise import GaussianNoise\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import keras\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "import numpy as np\n",
        "from keras.optimizers import Nadam,Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 150\n",
        "weight_decay=1e-4\n",
        "\n",
        "n_filters = 32         # number of convolutional filters to use\n",
        "kernel_size1 = (3, 3)  # shape of each convolutional filter\n",
        "kernel_size2 = (5, 5)\n",
        "kernel_size3 = (1, 1)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = np.reshape(train_images,(60000,28,28,1))/255.0\n",
        "test_images = np.reshape(test_images,(10000,28,28,1))/255.0\n",
        "\n",
        "input_shape = train_images.shape[1:]\n",
        "# convert class vectors to binary class matrices\n",
        "#Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "#Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "    # construct Keras model\n",
        "    \n",
        "def block_level1(inputX,l1,l2):\n",
        "    inputX=BatchNormalization()(inputX)\n",
        "    x1=Conv2D(l1, kernel_size1, padding='same',activation='elu',strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX)\n",
        "    x2=Conv2D(l2, kernel_size2, padding='same',activation='elu' ,strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX)\n",
        "    \n",
        "   \n",
        "    x1=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x1)\n",
        "    x2=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x2)\n",
        "    \n",
        "    x1=Dropout(0.25)(x1)\n",
        "    x2=Dropout(0.25)(x2)\n",
        "    \n",
        "    return x1,x2\n",
        "\n",
        "def block_tri_level(inputX1,inputX2,l1,l2):\n",
        "    inputX1=BatchNormalization()(inputX1)\n",
        "    inputX2=BatchNormalization()(inputX2)\n",
        "    \n",
        "    C=Concatenate(axis=3)([inputX1,inputX2])\n",
        "    x1=Conv2D(l1, kernel_size1, padding='same',activation='elu', strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(C)\n",
        "    x2=Conv2D(l2, kernel_size2, padding='same',activation='elu', strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX2)\n",
        "    \n",
        "    \n",
        "    \n",
        "   \n",
        "    x1=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x1)\n",
        "    x2=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x2)\n",
        "    \n",
        "    x1=Dropout(0.25)(x1)\n",
        "    x2=Dropout(0.25)(x2)\n",
        "    \n",
        "    return x1,x2\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "#x=GaussianNoise(0.1, input_shape=input_shape)(inputs)\n",
        "\n",
        "x1,x2=block_level1(inputs,256,256)\n",
        "x1,x2=block_tri_level(x1,x2,128,128)\n",
        "x1,x2=block_tri_level(x1,x2,64,64)\n",
        "x=Concatenate(axis=3)([x1,x2])\n",
        "\n",
        "x=Flatten()(x)\n",
        "\n",
        "x=BatchNormalization()(x)\n",
        "x=Dense(512,activation='relu')(x)\n",
        "Dropout(0.25)(x)\n",
        "\n",
        "x=BatchNormalization()(x)\n",
        "x=Dense(256,activation='relu')(x)\n",
        "Dropout(0.25)(x)\n",
        "\n",
        "\n",
        "x=Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "kmodel = Model(inputs, x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "kmodel.summary()\n",
        "\n",
        "lrr=1e-4\n",
        "\n",
        "#model_optimizer = Adam(lr=1E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "lrr=1e-4\n",
        "epochs=150\n",
        "model_optimizer=tensorflow.keras.optimizers.Nadam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "\n",
        "kmodel.compile(loss='categorical_crossentropy', optimizer=model_optimizer, metrics=['accuracy'])\n",
        "\n",
        "#fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "\n",
        "\n",
        "y = np.zeros((60000,10))\n",
        "y[np.arange(60000),train_labels]=1\n",
        "yt = np.zeros((10000,10))\n",
        "yt[np.arange(10000),test_labels]=1\n",
        "print(yt.shape)\n",
        "print(type(yt))\n",
        "\n",
        "kmodelHistory=kmodel.fit(x=train_images, y=y, batch_size=120, epochs=150, verbose=1,validation_data=(test_images, yt))\n",
        "\n",
        "\n",
        "# compile and fit Keras model\n",
        "#optimizer = tensorflow.keras.optimizers.Nadam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "#kmodel.compile(loss='categorical_crossentropy',           optimizer=optimizer,         metrics=['accuracy'])\n",
        "#kmodelHistory=kmodel.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "score = kmodel.evaluate(test_images, yt, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " #model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
        "#\t\tepochs=10, batch_size=64)\n",
        "  \n",
        "\n",
        "# compile and fit Keras model\n",
        "#optimizer = tensorflow.keras.optimizers.Nadam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "#kmodel.compile(loss='categorical_crossentropy',           optimizer=optimizer,         metrics=['accuracy'])\n",
        "#kmodelHistory=kmodel.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "#score = kmodel.evaluate(test_images, yt, verbose=0)\n",
        "#print('Test score:', score[0])\n",
        "#print('Test accuracy:', score[1])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 28, 28, 1)    4           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 28, 28, 256)  2560        batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 28, 28, 256)  6656        batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 14, 14, 256)  0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 14, 14, 256)  0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 14, 14, 256)  0           average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 14, 14, 256)  0           average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 256)  1024        dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 14, 14, 512)  0           batch_normalization_29[0][0]     \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 128)  589952      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 14, 14, 128)  819328      batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 7, 7, 128)    0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_27 (AveragePo (None, 7, 7, 128)    0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 7, 7, 128)    0           average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 7, 7, 128)    0           average_pooling2d_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    512         dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    512         dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 7, 7, 256)    0           batch_normalization_31[0][0]     \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 7, 7, 64)     147520      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 64)     204864      batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_28 (AveragePo (None, 4, 4, 64)     0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_29 (AveragePo (None, 4, 4, 64)     0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 4, 4, 64)     0           average_pooling2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 4, 4, 64)     0           average_pooling2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 4, 4, 128)    0           dropout_36[0][0]                 \n",
            "                                                                 dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 2048)         0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 2048)         8192        flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 512)          1049088     batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 512)          2048        dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 256)          131328      batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 10)           2570        dense_13[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,967,182\n",
            "Trainable params: 2,960,524\n",
            "Non-trainable params: 6,658\n",
            "__________________________________________________________________________________________________\n",
            "(10000, 10)\n",
            "<class 'numpy.ndarray'>\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/150\n",
            "60000/60000 [==============================] - 23s 381us/sample - loss: 0.3049 - acc: 0.9236 - val_loss: 0.5166 - val_acc: 0.8371\n",
            "Epoch 2/150\n",
            "60000/60000 [==============================] - 21s 348us/sample - loss: 0.1352 - acc: 0.9759 - val_loss: 0.0961 - val_acc: 0.9857\n",
            "Epoch 3/150\n",
            "60000/60000 [==============================] - 21s 348us/sample - loss: 0.1119 - acc: 0.9828 - val_loss: 0.0819 - val_acc: 0.9908\n",
            "Epoch 4/150\n",
            "60000/60000 [==============================] - 21s 347us/sample - loss: 0.0988 - acc: 0.9860 - val_loss: 0.0781 - val_acc: 0.9921\n",
            "Epoch 5/150\n",
            "60000/60000 [==============================] - 21s 349us/sample - loss: 0.0905 - acc: 0.9878 - val_loss: 0.0763 - val_acc: 0.9917\n",
            "Epoch 6/150\n",
            "60000/60000 [==============================] - 21s 347us/sample - loss: 0.0818 - acc: 0.9908 - val_loss: 0.0717 - val_acc: 0.9930\n",
            "Epoch 7/150\n",
            "60000/60000 [==============================] - 21s 347us/sample - loss: 0.0766 - acc: 0.9915 - val_loss: 0.0673 - val_acc: 0.9932\n",
            "Epoch 8/150\n",
            "60000/60000 [==============================] - 21s 346us/sample - loss: 0.0724 - acc: 0.9921 - val_loss: 0.0655 - val_acc: 0.9937\n",
            "Epoch 9/150\n",
            "60000/60000 [==============================] - 21s 346us/sample - loss: 0.0676 - acc: 0.9928 - val_loss: 0.0632 - val_acc: 0.9938\n",
            "Epoch 10/150\n",
            "60000/60000 [==============================] - 21s 345us/sample - loss: 0.0626 - acc: 0.9934 - val_loss: 0.0631 - val_acc: 0.9928\n",
            "Epoch 11/150\n",
            "60000/60000 [==============================] - 21s 345us/sample - loss: 0.0603 - acc: 0.9937 - val_loss: 0.0595 - val_acc: 0.9937\n",
            "Epoch 12/150\n",
            "60000/60000 [==============================] - 21s 347us/sample - loss: 0.0558 - acc: 0.9946 - val_loss: 0.0586 - val_acc: 0.9928\n",
            "Epoch 13/150\n",
            "60000/60000 [==============================] - 21s 345us/sample - loss: 0.0509 - acc: 0.9953 - val_loss: 0.0549 - val_acc: 0.9926\n",
            "Epoch 14/150\n",
            "60000/60000 [==============================] - 21s 345us/sample - loss: 0.0490 - acc: 0.9951 - val_loss: 0.0531 - val_acc: 0.9939\n",
            "Epoch 15/150\n",
            "60000/60000 [==============================] - 21s 347us/sample - loss: 0.0452 - acc: 0.9957 - val_loss: 0.0525 - val_acc: 0.9932\n",
            "Epoch 16/150\n",
            "60000/60000 [==============================] - 21s 345us/sample - loss: 0.0421 - acc: 0.9963 - val_loss: 0.0516 - val_acc: 0.9924\n",
            "Epoch 17/150\n",
            "60000/60000 [==============================] - 21s 345us/sample - loss: 0.0400 - acc: 0.9962 - val_loss: 0.0485 - val_acc: 0.9929\n",
            "Epoch 18/150\n",
            "60000/60000 [==============================] - 21s 346us/sample - loss: 0.0384 - acc: 0.9962 - val_loss: 0.0463 - val_acc: 0.9935\n",
            "Epoch 19/150\n",
            "60000/60000 [==============================] - 21s 347us/sample - loss: 0.0361 - acc: 0.9966 - val_loss: 0.0426 - val_acc: 0.9934\n",
            "Epoch 20/150\n",
            "60000/60000 [==============================] - 21s 345us/sample - loss: 0.0329 - acc: 0.9971 - val_loss: 0.0444 - val_acc: 0.9927\n",
            "Epoch 21/150\n",
            "60000/60000 [==============================] - 21s 346us/sample - loss: 0.0320 - acc: 0.9970 - val_loss: 0.0461 - val_acc: 0.9922\n",
            "Epoch 22/150\n",
            "60000/60000 [==============================] - 21s 352us/sample - loss: 0.0311 - acc: 0.9969 - val_loss: 0.0445 - val_acc: 0.9922\n",
            "Epoch 23/150\n",
            " 8520/60000 [===>..........................] - ETA: 17s - loss: 0.0306 - acc: 0.9969"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVT2yA3ExK4f"
      },
      "source": [
        "# > Densenet MNIST score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EjY17fscxK4h",
        "outputId": "8e3acc3e-7a35-4422-a7e6-2cd123ebe106"
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, GlobalAveragePooling2D, Dense, concatenate, AveragePooling2D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.core import Activation, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "from keras.optimizers import Nadam,Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "class DenseNet:\n",
        "    def __init__(self, input_shape=None, dense_blocks=3, dense_layers=-1, growth_rate=12, nb_classes=None,\n",
        "                 dropout_rate=None, bottleneck=False, compression=1.0, weight_decay=1e-4, depth=40):\n",
        "\n",
        "        # Checks\n",
        "        if nb_classes == None:\n",
        "            raise Exception( 'Please define number of classes (e.g. num_classes=10). This is required for final softmax.')\n",
        "\n",
        "        if compression <= 0.0 or compression > 1.0:\n",
        "            raise Exception('Compression have to be a value between 0.0 and 1.0.')\n",
        "\n",
        "        if type(dense_layers) is list:\n",
        "            if len(dense_layers) != dense_blocks:\n",
        "                raise AssertionError('Number of dense blocks have to be same length to specified layers')\n",
        "        elif dense_layers == -1:\n",
        "            dense_layers = int((depth - 4) / 3)\n",
        "            if bottleneck:\n",
        "                dense_layers = int(dense_layers / 2)\n",
        "            dense_layers = [dense_layers for _ in range(dense_blocks)]\n",
        "        else:\n",
        "            dense_layers = [dense_layers for _ in range(dense_blocks)]\n",
        "\n",
        "        self.dense_blocks = dense_blocks\n",
        "        self.dense_layers = dense_layers\n",
        "        self.input_shape = input_shape\n",
        "        self.growth_rate = growth_rate\n",
        "        self.weight_decay = weight_decay\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.bottleneck = bottleneck\n",
        "        self.compression = compression\n",
        "        self.nb_classes = nb_classes\n",
        "        \n",
        "    def build_model(self):\n",
        "        img_input = Input(shape=self.input_shape, name='img_input')\n",
        "        nb_channels = self.growth_rate\n",
        "        \n",
        "        x = Conv2D(2*self.growth_rate, (3,3), \n",
        "                   padding='same', strides = (1,1), \n",
        "                   kernel_regularizer=keras.regularizers.l2(self.weight_decay))(img_input)\n",
        "        \n",
        "        for block in range(self.dense_blocks-1):\n",
        "            x, nb_channels = self.dense_block(x, self.dense_layers[block], nb_channels, self.growth_rate,\n",
        "                                              self.dropout_rate, self.bottleneck, self.weight_decay)\n",
        "            \n",
        "            x = self.transition_layer(x, nb_channels, self.dropout_rate, self.compression, self.weight_decay)\n",
        "            nb_channels = int(nb_channels*self.compression)\n",
        "            \n",
        "        x, nb_channels = self.dense_block(x, self.dense_layers[-1], nb_channels, self.growth_rate, self.dropout_rate, self.weight_decay)\n",
        "        \n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        prediction = Dense(self.nb_classes, activation='softmax')(x)\n",
        "        \n",
        "        return Model(inputs=img_input, outputs=prediction, name='densenet')\n",
        "        \n",
        "    def dense_block(self, x, nb_layers, nb_channels, growth_rate, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n",
        "        for i in range(nb_layers):\n",
        "            cb = self.convolution_block(x, growth_rate, dropout_rate, bottleneck)\n",
        "            nb_channels += growth_rate\n",
        "            x = concatenate([cb,x])\n",
        "            \n",
        "        return x, nb_channels\n",
        "    \n",
        "    def convolution_block(self, x, nb_channels, dropout_rate=None, bottleneck=False, weight_decay=1e-4):       \n",
        "\n",
        "        # Bottleneck\n",
        "        if bottleneck:\n",
        "            bottleneckWidth = 4\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "            x = Conv2D(nb_channels * bottleneckWidth, (1, 1),\n",
        "                                     kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
        "            # Dropout\n",
        "            if dropout_rate:\n",
        "                x = Dropout(dropout_rate)(x)\n",
        "\n",
        "        # Standard (BN-ReLU-Conv)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2D(nb_channels, (3, 3), padding='same')(x)\n",
        "\n",
        "        # Dropout\n",
        "        if dropout_rate:\n",
        "            x = Dropout(dropout_rate)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def transition_layer(self, x, nb_channels, dropout_rate=None, compression=1.0, weight_decay=1e-4):\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2D(int(nb_channels * compression), (1, 1), padding='same',\n",
        "                                 kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
        "\n",
        "        # Adding dropout\n",
        "        if dropout_rate:\n",
        "            x = Dropout(dropout_rate)(x)\n",
        "\n",
        "        x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
        "        return x\n",
        "    \n",
        "    \n",
        "densenet = DenseNet((28,28,1), nb_classes=10, depth=35)\n",
        "\n",
        "model = densenet.build_model()\n",
        "\n",
        "#model_optimizer = Adam(lr=1E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "lrr=1e-4\n",
        "epochs=150\n",
        "model_optimizer=Adam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=model_optimizer, metrics=['accuracy'])\n",
        "\n",
        "#fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = np.reshape(train_images,(60000,28,28,1))\n",
        "test_images = np.reshape(test_images,(10000,28,28,1))\n",
        "\n",
        "y = np.zeros((60000,10))\n",
        "y[np.arange(60000),train_labels]=1\n",
        "yt = np.zeros((10000,10))\n",
        "yt[np.arange(10000),test_labels]=1\n",
        "print(yt.shape)\n",
        "print(type(yt))\n",
        "\n",
        "model.fit(x=train_images, y=y, batch_size=100, epochs=150, verbose=1,validation_data=(test_images, yt))\n",
        "#model.fit(X_train, y, batch_size=batch_size, epochs=epochs, verbose=1)#, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "<class 'numpy.ndarray'>\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/150\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 0.5327 - acc: 0.9151 - val_loss: 0.2156 - val_acc: 0.9747\n",
            "Epoch 2/150\n",
            "60000/60000 [==============================] - 53s 887us/step - loss: 0.1722 - acc: 0.9857 - val_loss: 0.1928 - val_acc: 0.9755\n",
            "Epoch 3/150\n",
            "60000/60000 [==============================] - 53s 889us/step - loss: 0.1421 - acc: 0.9895 - val_loss: 0.1495 - val_acc: 0.9843\n",
            "Epoch 4/150\n",
            "60000/60000 [==============================] - 53s 889us/step - loss: 0.1227 - acc: 0.9918 - val_loss: 0.1814 - val_acc: 0.9728\n",
            "Epoch 5/150\n",
            "60000/60000 [==============================] - 53s 887us/step - loss: 0.1107 - acc: 0.9928 - val_loss: 0.1767 - val_acc: 0.9676\n",
            "Epoch 6/150\n",
            "60000/60000 [==============================] - 53s 885us/step - loss: 0.0999 - acc: 0.9940 - val_loss: 0.3710 - val_acc: 0.8997\n",
            "Epoch 7/150\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0922 - acc: 0.9946 - val_loss: 0.2785 - val_acc: 0.9379\n",
            "Epoch 8/150\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0868 - acc: 0.9948 - val_loss: 0.1479 - val_acc: 0.9754\n",
            "Epoch 9/150\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0790 - acc: 0.9963 - val_loss: 0.0950 - val_acc: 0.9903\n",
            "Epoch 10/150\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0763 - acc: 0.9957 - val_loss: 0.1138 - val_acc: 0.9818\n",
            "Epoch 11/150\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0713 - acc: 0.9964 - val_loss: 0.1967 - val_acc: 0.9564\n",
            "Epoch 12/150\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0667 - acc: 0.9973 - val_loss: 0.0896 - val_acc: 0.9891\n",
            "Epoch 13/150\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0643 - acc: 0.9968 - val_loss: 0.0799 - val_acc: 0.9913\n",
            "Epoch 14/150\n",
            "60000/60000 [==============================] - 53s 883us/step - loss: 0.0603 - acc: 0.9973 - val_loss: 0.1045 - val_acc: 0.9846\n",
            "Epoch 15/150\n",
            "60000/60000 [==============================] - 53s 885us/step - loss: 0.0587 - acc: 0.9971 - val_loss: 0.0759 - val_acc: 0.9922\n",
            "Epoch 16/150\n",
            "60000/60000 [==============================] - 53s 882us/step - loss: 0.0556 - acc: 0.9975 - val_loss: 0.0815 - val_acc: 0.9896\n",
            "Epoch 17/150\n",
            "60000/60000 [==============================] - 53s 879us/step - loss: 0.0535 - acc: 0.9975 - val_loss: 0.1248 - val_acc: 0.9751\n",
            "Epoch 18/150\n",
            "60000/60000 [==============================] - 53s 883us/step - loss: 0.0523 - acc: 0.9973 - val_loss: 0.2876 - val_acc: 0.9255\n",
            "Epoch 19/150\n",
            "60000/60000 [==============================] - 53s 884us/step - loss: 0.0493 - acc: 0.9981 - val_loss: 0.0755 - val_acc: 0.9890\n",
            "Epoch 20/150\n",
            "60000/60000 [==============================] - 53s 885us/step - loss: 0.0467 - acc: 0.9984 - val_loss: 0.1860 - val_acc: 0.9599\n",
            "Epoch 21/150\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0450 - acc: 0.9984 - val_loss: 0.0635 - val_acc: 0.9931\n",
            "Epoch 22/150\n",
            "60000/60000 [==============================] - 53s 880us/step - loss: 0.0439 - acc: 0.9984 - val_loss: 0.0608 - val_acc: 0.9932\n",
            "Epoch 23/150\n",
            "60000/60000 [==============================] - 53s 881us/step - loss: 0.0432 - acc: 0.9978 - val_loss: 0.0762 - val_acc: 0.9877\n",
            "Epoch 24/150\n",
            "60000/60000 [==============================] - 53s 882us/step - loss: 0.0394 - acc: 0.9988 - val_loss: 0.0975 - val_acc: 0.9819\n",
            "Epoch 25/150\n",
            "60000/60000 [==============================] - 53s 887us/step - loss: 0.0393 - acc: 0.9983 - val_loss: 0.1357 - val_acc: 0.9688\n",
            "Epoch 26/150\n",
            "60000/60000 [==============================] - 53s 880us/step - loss: 0.0387 - acc: 0.9984 - val_loss: 0.0569 - val_acc: 0.9924\n",
            "Epoch 27/150\n",
            "60000/60000 [==============================] - 53s 884us/step - loss: 0.0357 - acc: 0.9990 - val_loss: 0.0588 - val_acc: 0.9920\n",
            "Epoch 28/150\n",
            "60000/60000 [==============================] - 53s 885us/step - loss: 0.0357 - acc: 0.9984 - val_loss: 0.0739 - val_acc: 0.9856\n",
            "Epoch 29/150\n",
            "60000/60000 [==============================] - 53s 885us/step - loss: 0.0326 - acc: 0.9990 - val_loss: 0.0823 - val_acc: 0.9839\n",
            "Epoch 30/150\n",
            "60000/60000 [==============================] - 53s 883us/step - loss: 0.0335 - acc: 0.9984 - val_loss: 0.1307 - val_acc: 0.9687\n",
            "Epoch 31/150\n",
            "60000/60000 [==============================] - 53s 885us/step - loss: 0.0326 - acc: 0.9984 - val_loss: 0.0445 - val_acc: 0.9950\n",
            "Epoch 32/150\n",
            "60000/60000 [==============================] - 53s 881us/step - loss: 0.0300 - acc: 0.9989 - val_loss: 0.0514 - val_acc: 0.9936\n",
            "Epoch 33/150\n",
            "60000/60000 [==============================] - 53s 881us/step - loss: 0.0295 - acc: 0.9988 - val_loss: 0.0808 - val_acc: 0.9819\n",
            "Epoch 34/150\n",
            "60000/60000 [==============================] - 53s 879us/step - loss: 0.0286 - acc: 0.9990 - val_loss: 0.0652 - val_acc: 0.9883\n",
            "Epoch 35/150\n",
            "60000/60000 [==============================] - 53s 880us/step - loss: 0.0288 - acc: 0.9985 - val_loss: 0.0535 - val_acc: 0.9917\n",
            "Epoch 36/150\n",
            "60000/60000 [==============================] - 53s 883us/step - loss: 0.0270 - acc: 0.9990 - val_loss: 0.0388 - val_acc: 0.9957\n",
            "Epoch 37/150\n",
            "60000/60000 [==============================] - 53s 882us/step - loss: 0.0247 - acc: 0.9995 - val_loss: 0.0514 - val_acc: 0.9915\n",
            "Epoch 38/150\n",
            "60000/60000 [==============================] - 53s 883us/step - loss: 0.0250 - acc: 0.9990 - val_loss: 0.1080 - val_acc: 0.9768\n",
            "Epoch 39/150\n",
            "60000/60000 [==============================] - 53s 880us/step - loss: 0.0254 - acc: 0.9987 - val_loss: 0.2685 - val_acc: 0.9258\n",
            "Epoch 40/150\n",
            "60000/60000 [==============================] - 53s 879us/step - loss: 0.0238 - acc: 0.9991 - val_loss: 0.0951 - val_acc: 0.9812\n",
            "Epoch 41/150\n",
            "60000/60000 [==============================] - 53s 877us/step - loss: 0.0230 - acc: 0.9993 - val_loss: 0.3896 - val_acc: 0.9008\n",
            "Epoch 42/150\n",
            "60000/60000 [==============================] - 53s 882us/step - loss: 0.0214 - acc: 0.9994 - val_loss: 0.1179 - val_acc: 0.9707\n",
            "Epoch 43/150\n",
            "60000/60000 [==============================] - 53s 877us/step - loss: 0.0232 - acc: 0.9986 - val_loss: 0.0434 - val_acc: 0.9931\n",
            "Epoch 44/150\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0216 - acc: 0.9990 - val_loss: 0.0562 - val_acc: 0.9884\n",
            "Epoch 45/150\n",
            "60000/60000 [==============================] - 54s 906us/step - loss: 0.0198 - acc: 0.9994 - val_loss: 0.0885 - val_acc: 0.9805\n",
            "Epoch 46/150\n",
            "60000/60000 [==============================] - 55s 913us/step - loss: 0.0191 - acc: 0.9994 - val_loss: 0.0892 - val_acc: 0.9824\n",
            "Epoch 47/150\n",
            "60000/60000 [==============================] - 55s 912us/step - loss: 0.0221 - acc: 0.9981 - val_loss: 0.0422 - val_acc: 0.9923\n",
            "Epoch 48/150\n",
            "60000/60000 [==============================] - 55s 921us/step - loss: 0.0190 - acc: 0.9991 - val_loss: 0.0420 - val_acc: 0.9918\n",
            "Epoch 49/150\n",
            "60000/60000 [==============================] - 55s 923us/step - loss: 0.0188 - acc: 0.9992 - val_loss: 0.0514 - val_acc: 0.9904\n",
            "Epoch 50/150\n",
            "60000/60000 [==============================] - 55s 915us/step - loss: 0.0175 - acc: 0.9994 - val_loss: 0.0634 - val_acc: 0.9878\n",
            "Epoch 51/150\n",
            "60000/60000 [==============================] - 55s 914us/step - loss: 0.0167 - acc: 0.9995 - val_loss: 0.0430 - val_acc: 0.9919\n",
            "Epoch 52/150\n",
            "60000/60000 [==============================] - 55s 912us/step - loss: 0.0163 - acc: 0.9995 - val_loss: 0.0371 - val_acc: 0.9938\n",
            "Epoch 53/150\n",
            "60000/60000 [==============================] - 55s 911us/step - loss: 0.0190 - acc: 0.9985 - val_loss: 0.0557 - val_acc: 0.9883\n",
            "Epoch 54/150\n",
            "60000/60000 [==============================] - 54s 899us/step - loss: 0.0152 - acc: 0.9998 - val_loss: 0.0324 - val_acc: 0.9950\n",
            "Epoch 55/150\n",
            "60000/60000 [==============================] - 54s 899us/step - loss: 0.0150 - acc: 0.9995 - val_loss: 0.0363 - val_acc: 0.9942\n",
            "Epoch 56/150\n",
            "60000/60000 [==============================] - 54s 894us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 0.0515 - val_acc: 0.9898\n",
            "Epoch 57/150\n",
            "60000/60000 [==============================] - 54s 896us/step - loss: 0.0135 - acc: 0.9998 - val_loss: 0.0530 - val_acc: 0.9894\n",
            "Epoch 58/150\n",
            "60000/60000 [==============================] - 54s 903us/step - loss: 0.0163 - acc: 0.9987 - val_loss: 0.0922 - val_acc: 0.9782\n",
            "Epoch 59/150\n",
            "60000/60000 [==============================] - 54s 904us/step - loss: 0.0153 - acc: 0.9990 - val_loss: 0.0329 - val_acc: 0.9931\n",
            "Epoch 60/150\n",
            "60000/60000 [==============================] - 54s 898us/step - loss: 0.0135 - acc: 0.9995 - val_loss: 0.0387 - val_acc: 0.9930\n",
            "Epoch 61/150\n",
            "60000/60000 [==============================] - 54s 902us/step - loss: 0.0133 - acc: 0.9995 - val_loss: 0.1318 - val_acc: 0.9655\n",
            "Epoch 62/150\n",
            "60000/60000 [==============================] - 54s 896us/step - loss: 0.0146 - acc: 0.9990 - val_loss: 0.0398 - val_acc: 0.9924\n",
            "Epoch 63/150\n",
            "60000/60000 [==============================] - 54s 899us/step - loss: 0.0130 - acc: 0.9994 - val_loss: 0.0588 - val_acc: 0.9883\n",
            "Epoch 64/150\n",
            "60000/60000 [==============================] - 54s 899us/step - loss: 0.0130 - acc: 0.9992 - val_loss: 0.0830 - val_acc: 0.9818\n",
            "Epoch 65/150\n",
            "60000/60000 [==============================] - 54s 900us/step - loss: 0.0123 - acc: 0.9995 - val_loss: 0.0343 - val_acc: 0.9940\n",
            "Epoch 66/150\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0131 - acc: 0.9992 - val_loss: 0.0710 - val_acc: 0.9859\n",
            "Epoch 67/150\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0110 - acc: 0.9997 - val_loss: 0.1131 - val_acc: 0.9755\n",
            "Epoch 68/150\n",
            "60000/60000 [==============================] - 53s 889us/step - loss: 0.0115 - acc: 0.9995 - val_loss: 0.1162 - val_acc: 0.9724\n",
            "Epoch 69/150\n",
            "60000/60000 [==============================] - 53s 888us/step - loss: 0.0117 - acc: 0.9994 - val_loss: 0.1215 - val_acc: 0.9658\n",
            "Epoch 70/150\n",
            "60000/60000 [==============================] - 54s 893us/step - loss: 0.0118 - acc: 0.9992 - val_loss: 0.1212 - val_acc: 0.9705\n",
            "Epoch 71/150\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0110 - acc: 0.9995 - val_loss: 0.0287 - val_acc: 0.9956\n",
            "Epoch 72/150\n",
            "60000/60000 [==============================] - 53s 889us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9958\n",
            "Epoch 73/150\n",
            "60000/60000 [==============================] - 53s 886us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 0.9961\n",
            "Epoch 74/150\n",
            "60000/60000 [==============================] - 53s 889us/step - loss: 0.0089 - acc: 0.9997 - val_loss: 1.2755 - val_acc: 0.7679\n",
            "Epoch 75/150\n",
            "60000/60000 [==============================] - 54s 896us/step - loss: 0.0143 - acc: 0.9979 - val_loss: 0.0348 - val_acc: 0.9929\n",
            "Epoch 76/150\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0090 - acc: 0.9997 - val_loss: 0.0267 - val_acc: 0.9951\n",
            "Epoch 77/150\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0100 - acc: 0.9993 - val_loss: 0.0328 - val_acc: 0.9937\n",
            "Epoch 78/150\n",
            "60000/60000 [==============================] - 54s 903us/step - loss: 0.0103 - acc: 0.9991 - val_loss: 0.0415 - val_acc: 0.9911\n",
            "Epoch 79/150\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0081 - acc: 0.9998 - val_loss: 0.0316 - val_acc: 0.9941\n",
            "Epoch 80/150\n",
            "60000/60000 [==============================] - 55s 919us/step - loss: 0.0101 - acc: 0.9990 - val_loss: 0.0543 - val_acc: 0.9874\n",
            "Epoch 81/150\n",
            "60000/60000 [==============================] - 55s 918us/step - loss: 0.0090 - acc: 0.9995 - val_loss: 0.0469 - val_acc: 0.9885\n",
            "Epoch 82/150\n",
            "60000/60000 [==============================] - 55s 913us/step - loss: 0.0082 - acc: 0.9997 - val_loss: 0.0480 - val_acc: 0.9893\n",
            "Epoch 83/150\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0098 - acc: 0.9993 - val_loss: 0.0281 - val_acc: 0.9945\n",
            "Epoch 84/150\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9955\n",
            "Epoch 85/150\n",
            "60000/60000 [==============================] - 54s 905us/step - loss: 0.0094 - acc: 0.9991 - val_loss: 0.0456 - val_acc: 0.9900\n",
            "Epoch 86/150\n",
            "60000/60000 [==============================] - 54s 899us/step - loss: 0.0075 - acc: 0.9998 - val_loss: 0.0281 - val_acc: 0.9945\n",
            "Epoch 87/150\n",
            "60000/60000 [==============================] - 55s 908us/step - loss: 0.0084 - acc: 0.9993 - val_loss: 0.0584 - val_acc: 0.9882\n",
            "Epoch 88/150\n",
            "60000/60000 [==============================] - 55s 913us/step - loss: 0.0087 - acc: 0.9993 - val_loss: 0.0693 - val_acc: 0.9825\n",
            "Epoch 89/150\n",
            "60000/60000 [==============================] - 55s 909us/step - loss: 0.0075 - acc: 0.9997 - val_loss: 0.0239 - val_acc: 0.9956\n",
            "Epoch 90/150\n",
            "60000/60000 [==============================] - 54s 901us/step - loss: 0.0070 - acc: 0.9998 - val_loss: 0.0232 - val_acc: 0.9952\n",
            "Epoch 91/150\n",
            "60000/60000 [==============================] - 54s 907us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9948\n",
            "Epoch 92/150\n",
            "60000/60000 [==============================] - 54s 908us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9966\n",
            "Epoch 93/150\n",
            "60000/60000 [==============================] - 54s 902us/step - loss: 0.0103 - acc: 0.9985 - val_loss: 0.0396 - val_acc: 0.9910\n",
            "Epoch 94/150\n",
            "60000/60000 [==============================] - 54s 908us/step - loss: 0.0073 - acc: 0.9994 - val_loss: 0.0350 - val_acc: 0.9929\n",
            "Epoch 95/150\n",
            "60000/60000 [==============================] - 54s 906us/step - loss: 0.0077 - acc: 0.9993 - val_loss: 0.0652 - val_acc: 0.9866\n",
            "Epoch 96/150\n",
            "60000/60000 [==============================] - 55s 909us/step - loss: 0.0064 - acc: 0.9998 - val_loss: 0.0314 - val_acc: 0.9927\n",
            "Epoch 97/150\n",
            "60000/60000 [==============================] - 55s 909us/step - loss: 0.0059 - acc: 0.9999 - val_loss: 0.0234 - val_acc: 0.9958\n",
            "Epoch 98/150\n",
            "60000/60000 [==============================] - 55s 910us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 1.0720 - val_acc: 0.8373\n",
            "Epoch 99/150\n",
            "60000/60000 [==============================] - 54s 901us/step - loss: 0.0093 - acc: 0.9988 - val_loss: 0.0280 - val_acc: 0.9940\n",
            "Epoch 100/150\n",
            "60000/60000 [==============================] - 54s 903us/step - loss: 0.0066 - acc: 0.9996 - val_loss: 0.0502 - val_acc: 0.9888\n",
            "Epoch 101/150\n",
            "60000/60000 [==============================] - 54s 905us/step - loss: 0.0055 - acc: 0.9999 - val_loss: 0.0212 - val_acc: 0.9956\n",
            "Epoch 102/150\n",
            "60000/60000 [==============================] - 54s 898us/step - loss: 0.0052 - acc: 0.9999 - val_loss: 0.1548 - val_acc: 0.9626\n",
            "Epoch 103/150\n",
            "60000/60000 [==============================] - 54s 902us/step - loss: 0.0088 - acc: 0.9988 - val_loss: 0.0811 - val_acc: 0.9814\n",
            "Epoch 104/150\n",
            "60000/60000 [==============================] - 54s 903us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 0.9943\n",
            "Epoch 105/150\n",
            "60000/60000 [==============================] - 54s 902us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.0261 - val_acc: 0.9945\n",
            "Epoch 106/150\n",
            "60000/60000 [==============================] - 54s 903us/step - loss: 0.0068 - acc: 0.9994 - val_loss: 0.3140 - val_acc: 0.9402\n",
            "Epoch 107/150\n",
            "60000/60000 [==============================] - 54s 907us/step - loss: 0.0065 - acc: 0.9995 - val_loss: 0.0529 - val_acc: 0.9879\n",
            "Epoch 108/150\n",
            "60000/60000 [==============================] - 54s 907us/step - loss: 0.0055 - acc: 0.9997 - val_loss: 0.0350 - val_acc: 0.9934\n",
            "Epoch 109/150\n",
            "60000/60000 [==============================] - 54s 907us/step - loss: 0.0073 - acc: 0.9992 - val_loss: 0.0242 - val_acc: 0.9946\n",
            "Epoch 110/150\n",
            "60000/60000 [==============================] - 54s 905us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9957\n",
            "Epoch 111/150\n",
            "60000/60000 [==============================] - 54s 907us/step - loss: 0.0047 - acc: 0.9999 - val_loss: 0.0452 - val_acc: 0.9905\n",
            "Epoch 112/150\n",
            "60000/60000 [==============================] - 54s 907us/step - loss: 0.0070 - acc: 0.9992 - val_loss: 0.0950 - val_acc: 0.9746\n",
            "Epoch 113/150\n",
            "60000/60000 [==============================] - 54s 907us/step - loss: 0.0050 - acc: 0.9998 - val_loss: 0.0204 - val_acc: 0.9957\n",
            "Epoch 114/150\n",
            "60000/60000 [==============================] - 54s 904us/step - loss: 0.0052 - acc: 0.9997 - val_loss: 0.0422 - val_acc: 0.9906\n",
            "Epoch 115/150\n",
            "60000/60000 [==============================] - 54s 901us/step - loss: 0.0059 - acc: 0.9994 - val_loss: 0.0342 - val_acc: 0.9928\n",
            "Epoch 116/150\n",
            "60000/60000 [==============================] - 54s 902us/step - loss: 0.0047 - acc: 0.9998 - val_loss: 0.0487 - val_acc: 0.9891\n",
            "Epoch 117/150\n",
            "60000/60000 [==============================] - 54s 901us/step - loss: 0.0059 - acc: 0.9995 - val_loss: 0.0284 - val_acc: 0.9935\n",
            "Epoch 118/150\n",
            "60000/60000 [==============================] - 54s 899us/step - loss: 0.0053 - acc: 0.9996 - val_loss: 0.2084 - val_acc: 0.9512\n",
            "Epoch 119/150\n",
            "60000/60000 [==============================] - 54s 895us/step - loss: 0.0052 - acc: 0.9996 - val_loss: 0.0224 - val_acc: 0.9952\n",
            "Epoch 120/150\n",
            "60000/60000 [==============================] - 53s 888us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.0253 - val_acc: 0.9947\n",
            "Epoch 121/150\n",
            "60000/60000 [==============================] - 53s 888us/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.0453 - val_acc: 0.9918\n",
            "Epoch 122/150\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0049 - acc: 0.9997 - val_loss: 0.0305 - val_acc: 0.9926\n",
            "Epoch 123/150\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 0.9955\n",
            "Epoch 124/150\n",
            "60000/60000 [==============================] - 53s 888us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9954\n",
            "Epoch 125/150\n",
            "60000/60000 [==============================] - 53s 889us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9957\n",
            "Epoch 126/150\n",
            "60000/60000 [==============================] - 53s 878us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9954\n",
            "Epoch 127/150\n",
            "60000/60000 [==============================] - 53s 881us/step - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0311 - val_acc: 0.9932\n",
            "Epoch 128/150\n",
            "60000/60000 [==============================] - 53s 879us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 0.0217 - val_acc: 0.9948\n",
            "Epoch 129/150\n",
            "60000/60000 [==============================] - 53s 878us/step - loss: 0.0051 - acc: 0.9995 - val_loss: 0.1399 - val_acc: 0.9673\n",
            "Epoch 130/150\n",
            "60000/60000 [==============================] - 53s 877us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0300 - val_acc: 0.9936\n",
            "Epoch 131/150\n",
            "60000/60000 [==============================] - 53s 875us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 0.9946\n",
            "Epoch 132/150\n",
            "60000/60000 [==============================] - 53s 878us/step - loss: 0.0042 - acc: 0.9997 - val_loss: 0.0289 - val_acc: 0.9934\n",
            "Epoch 133/150\n",
            "60000/60000 [==============================] - 53s 884us/step - loss: 0.0036 - acc: 0.9999 - val_loss: 0.0255 - val_acc: 0.9941\n",
            "Epoch 134/150\n",
            "60000/60000 [==============================] - 53s 879us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0427 - val_acc: 0.9910\n",
            "Epoch 135/150\n",
            "60000/60000 [==============================] - 53s 878us/step - loss: 0.0042 - acc: 0.9996 - val_loss: 0.0285 - val_acc: 0.9939\n",
            "Epoch 136/150\n",
            "60000/60000 [==============================] - 53s 876us/step - loss: 0.0036 - acc: 0.9999 - val_loss: 0.0225 - val_acc: 0.9956\n",
            "Epoch 137/150\n",
            "60000/60000 [==============================] - 53s 876us/step - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0448 - val_acc: 0.9887\n",
            "Epoch 138/150\n",
            "60000/60000 [==============================] - 52s 874us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0301 - val_acc: 0.9934\n",
            "Epoch 139/150\n",
            "60000/60000 [==============================] - 53s 877us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 0.0209 - val_acc: 0.9957\n",
            "Epoch 140/150\n",
            "60000/60000 [==============================] - 53s 879us/step - loss: 0.0046 - acc: 0.9996 - val_loss: 0.0201 - val_acc: 0.9951\n",
            "Epoch 141/150\n",
            "60000/60000 [==============================] - 53s 888us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 0.9956\n",
            "Epoch 142/150\n",
            "60000/60000 [==============================] - 52s 874us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 0.9957\n",
            "Epoch 143/150\n",
            "60000/60000 [==============================] - 53s 875us/step - loss: 0.0063 - acc: 0.9989 - val_loss: 0.0361 - val_acc: 0.9915\n",
            "Epoch 144/150\n",
            "60000/60000 [==============================] - 52s 873us/step - loss: 0.0037 - acc: 0.9998 - val_loss: 0.0254 - val_acc: 0.9942\n",
            "Epoch 145/150\n",
            "60000/60000 [==============================] - 53s 878us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9951\n",
            "Epoch 146/150\n",
            "60000/60000 [==============================] - 53s 883us/step - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0302 - val_acc: 0.9935\n",
            "Epoch 147/150\n",
            "60000/60000 [==============================] - 53s 877us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0407 - val_acc: 0.9899\n",
            "Epoch 148/150\n",
            "60000/60000 [==============================] - 53s 883us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.0183 - val_acc: 0.9960\n",
            "Epoch 149/150\n",
            "60000/60000 [==============================] - 52s 874us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9964\n",
            "Epoch 150/150\n",
            "60000/60000 [==============================] - 52s 873us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9956\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a60c40358>"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdVduEeqxK4l"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "score = model.evaluate(X_testM, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "accuracy = kmodelHistory.history['accuracy']\n",
        "val_accuracy = kmodelHistory.history['val_accuracy']\n",
        "loss = kmodelHistory.history['loss']\n",
        "val_loss = kmodelHistory.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, '-', label='Training accuracy',linewidth=2)\n",
        "plt.plot(epochs, val_accuracy, 'g',c='red', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, '-', label='Training loss',linewidth=2)\n",
        "plt.plot(epochs, val_loss, 'b',c='red', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iLvndzvQiwi-",
        "outputId": "87bc001d-ace9-4411-db7d-957d489e739a"
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, GlobalAveragePooling2D, Dense, concatenate, AveragePooling2D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.core import Activation, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "from keras.optimizers import Nadam,Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "class DenseNet:\n",
        "    def __init__(self, input_shape=None, dense_blocks=3, dense_layers=-1, growth_rate=12, nb_classes=None,\n",
        "                 dropout_rate=None, bottleneck=False, compression=1.0, weight_decay=1e-4, depth=40):\n",
        "\n",
        "        # Checks\n",
        "        if nb_classes == None:\n",
        "            raise Exception( 'Please define number of classes (e.g. num_classes=10). This is required for final softmax.')\n",
        "\n",
        "        if compression <= 0.0 or compression > 1.0:\n",
        "            raise Exception('Compression have to be a value between 0.0 and 1.0.')\n",
        "\n",
        "        if type(dense_layers) is list:\n",
        "            if len(dense_layers) != dense_blocks:\n",
        "                raise AssertionError('Number of dense blocks have to be same length to specified layers')\n",
        "        elif dense_layers == -1:\n",
        "            dense_layers = int((depth - 4) / 3)\n",
        "            if bottleneck:\n",
        "                dense_layers = int(dense_layers / 2)\n",
        "            dense_layers = [dense_layers for _ in range(dense_blocks)]\n",
        "        else:\n",
        "            dense_layers = [dense_layers for _ in range(dense_blocks)]\n",
        "\n",
        "        self.dense_blocks = dense_blocks\n",
        "        self.dense_layers = dense_layers\n",
        "        self.input_shape = input_shape\n",
        "        self.growth_rate = growth_rate\n",
        "        self.weight_decay = weight_decay\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.bottleneck = bottleneck\n",
        "        self.compression = compression\n",
        "        self.nb_classes = nb_classes\n",
        "        \n",
        "    def build_model(self):\n",
        "        img_input = Input(shape=self.input_shape, name='img_input')\n",
        "        nb_channels = self.growth_rate\n",
        "        \n",
        "        x = Conv2D(2*self.growth_rate, (3,3), \n",
        "                   padding='same', strides = (1,1), \n",
        "                   kernel_regularizer=keras.regularizers.l2(self.weight_decay))(img_input)\n",
        "        \n",
        "        for block in range(self.dense_blocks-1):\n",
        "            x, nb_channels = self.dense_block(x, self.dense_layers[block], nb_channels, self.growth_rate,\n",
        "                                              self.dropout_rate, self.bottleneck, self.weight_decay)\n",
        "            \n",
        "            x = self.transition_layer(x, nb_channels, self.dropout_rate, self.compression, self.weight_decay)\n",
        "            nb_channels = int(nb_channels*self.compression)\n",
        "            \n",
        "        x, nb_channels = self.dense_block(x, self.dense_layers[-1], nb_channels, self.growth_rate, self.dropout_rate, self.weight_decay)\n",
        "        \n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        prediction = Dense(self.nb_classes, activation='softmax')(x)\n",
        "        \n",
        "        return Model(inputs=img_input, outputs=prediction, name='densenet')\n",
        "        \n",
        "    def dense_block(self, x, nb_layers, nb_channels, growth_rate, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n",
        "        for i in range(nb_layers):\n",
        "            cb = self.convolution_block(x, growth_rate, dropout_rate, bottleneck)\n",
        "            nb_channels += growth_rate\n",
        "            x = concatenate([cb,x])\n",
        "            \n",
        "        return x, nb_channels\n",
        "    \n",
        "    def convolution_block(self, x, nb_channels, dropout_rate=None, bottleneck=False, weight_decay=1e-4):       \n",
        "\n",
        "        # Bottleneck\n",
        "        if bottleneck:\n",
        "            bottleneckWidth = 4\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "            x = Conv2D(nb_channels * bottleneckWidth, (1, 1),\n",
        "                                     kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
        "            # Dropout\n",
        "            if dropout_rate:\n",
        "                x = Dropout(dropout_rate)(x)\n",
        "\n",
        "        # Standard (BN-ReLU-Conv)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2D(nb_channels, (3, 3), padding='same')(x)\n",
        "\n",
        "        # Dropout\n",
        "        if dropout_rate:\n",
        "            x = Dropout(dropout_rate)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def transition_layer(self, x, nb_channels, dropout_rate=None, compression=1.0, weight_decay=1e-4):\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2D(int(nb_channels * compression), (1, 1), padding='same',\n",
        "                                 kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
        "\n",
        "        # Adding dropout\n",
        "        if dropout_rate:\n",
        "            x = Dropout(dropout_rate)(x)\n",
        "\n",
        "        x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
        "        return x\n",
        "    \n",
        "    \n",
        "densenet = DenseNet((28,28,1), nb_classes=10, depth=35)\n",
        "\n",
        "model = densenet.build_model()\n",
        "\n",
        "#model_optimizer = Adam(lr=1E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "lrr=1e-4\n",
        "epochs=150\n",
        "model_optimizer=Adam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=model_optimizer, metrics=['accuracy'])\n",
        "\n",
        "#fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = np.reshape(train_images,(60000,28,28,1))\n",
        "test_images = np.reshape(test_images,(10000,28,28,1))\n",
        "\n",
        "y = np.zeros((60000,10))\n",
        "y[np.arange(60000),train_labels]=1\n",
        "yt = np.zeros((10000,10))\n",
        "yt[np.arange(10000),test_labels]=1\n",
        "print(yt.shape)\n",
        "print(type(yt))\n",
        "\n",
        "model.fit(x=train_images, y=y, batch_size=100, epochs=150, verbose=1,validation_data=(test_images, yt))\n",
        "#model.fit(X_train, y, batch_size=batch_size, epochs=epochs, verbose=1)#, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "(10000, 10)\n",
            "<class 'numpy.ndarray'>\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/150\n",
            "11600/60000 [====>.........................] - ETA: 1:37 - loss: 1.4941 - acc: 0.6841"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f43948aa21b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;31m#model.fit(X_train, y, batch_size=batch_size, epochs=epochs, verbose=1)#, validation_data=(X_test, Y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIGwELbZgU4g"
      },
      "source": [
        "# **CIFAR Architecture en Z**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hBV2gMGZgacx",
        "outputId": "a8b8986a-e0f8-4084-c7fc-a2874e53350d"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "#from keras.optimizers import Nadam,Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import (Activation, Conv2D,GlobalAveragePooling2D, Dense, Dropout, Flatten,AvgPool2D,MaxPooling2D,LeakyReLU,Input,Concatenate,Subtract)\n",
        "from tensorflow.python.keras.layers.noise import GaussianNoise\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import keras\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 150\n",
        "weight_decay=1e-4\n",
        "\n",
        "n_filters = 32         # number of convolutional filters to use\n",
        "kernel_size1 = (3, 3)  # shape of each convolutional filter\n",
        "kernel_size2 = (5, 5)\n",
        "kernel_size3 = (1, 1)\n",
        "num_classes = 10\n",
        "\n",
        "print('x_train shape:', train_images.shape)\n",
        "print(train_images.shape[0], 'train samples')\n",
        "print(test_images.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(train_labels, num_classes)\n",
        "y_test = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#train_images = np.reshape(train_images,(60000,28,28,1))\n",
        "#test_images = np.reshape(test_images,(10000,28,28,1))\n",
        "\n",
        "input_shape = train_images.shape[1:]\n",
        "# convert class vectors to binary class matrices\n",
        "#Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "#Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "    # construct Keras model\n",
        "    \n",
        "def block_level1(inputX,l1,l2):\n",
        "    inputX=BatchNormalization()(inputX)\n",
        "    x1=Conv2D(l1, kernel_size1, padding='same',activation='relu',strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX)\n",
        "    x2=Conv2D(l2, kernel_size2, padding='same',activation='relu' ,strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX)\n",
        "    \n",
        "   \n",
        "    x1=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x1)\n",
        "    x2=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x2)\n",
        "    \n",
        "    x1=Dropout(0.25)(x1)\n",
        "    x2=Dropout(0.25)(x2)\n",
        "    \n",
        "    return x1,x2\n",
        "\n",
        "def block_tri_level(inputX1,inputX2,l1,l2):\n",
        "    inputX1=BatchNormalization()(inputX1)\n",
        "    inputX2=BatchNormalization()(inputX2)\n",
        "    \n",
        "    C=Concatenate(axis=3)([inputX1,inputX2])\n",
        "    x1=Conv2D(l1, kernel_size1, padding='same',activation='relu', strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(C)\n",
        "    x2=Conv2D(l2, kernel_size2, padding='same',activation='relu', strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX2)\n",
        "    \n",
        "    \n",
        "    \n",
        "   \n",
        "    x1=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x1)\n",
        "    x2=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x2)\n",
        "    \n",
        "    x1=Dropout(0.25)(x1)\n",
        "    x2=Dropout(0.25)(x2)\n",
        "    \n",
        "    return x1,x2\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "#x=GaussianNoise(0.1, input_shape=input_shape)(inputs)\n",
        "\n",
        "x1,x2=block_level1(inputs,256,128)\n",
        "x1,x2=block_tri_level(x1,x2,64,32)\n",
        "x1,x2=block_tri_level(x1,x2,45,16)\n",
        "x=Concatenate(axis=3)([x1,x2])\n",
        "\n",
        "x=Flatten()(x)\n",
        "\n",
        "x=BatchNormalization()(x)\n",
        "x=Dense(512,activation='relu')(x)\n",
        "Dropout(0.25)(x)\n",
        "\n",
        "x=BatchNormalization()(x)\n",
        "x=Dense(256,activation='relu')(x)\n",
        "Dropout(0.25)(x)\n",
        "\n",
        "\n",
        "x=Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "kmodel = Model(inputs, x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "kmodel.summary()\n",
        "\n",
        "lrr=1e-4\n",
        "\n",
        "#model_optimizer = Adam(lr=1E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "lrr=1e-4\n",
        "epochs=150\n",
        "model_optimizer=tensorflow.keras.optimizers.Nadam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "\n",
        "kmodel.compile(loss='categorical_crossentropy', optimizer=model_optimizer, metrics=['accuracy'])\n",
        "\n",
        "#fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "\n",
        "\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "#train_images /= 255\n",
        "#test_images /= 255\n",
        "\n",
        "kmodelHistory=kmodel.fit(x=train_images, y=y_train, batch_size=120, epochs=150, verbose=1,validation_data=(test_images, y_test))\n",
        "\n",
        "\n",
        "# compile and fit Keras model\n",
        "#optimizer = tensorflow.keras.optimizers.Nadam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09, decay=lrr/epochs)\n",
        "#kmodel.compile(loss='categorical_crossentropy',           optimizer=optimizer,         metrics=['accuracy'])\n",
        "#kmodelHistory=kmodel.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "score = kmodel.evaluate(test_images, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 32, 32, 3)    12          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 256)  7168        batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 128)  9728        batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_28 (AveragePo (None, 16, 16, 256)  0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_29 (AveragePo (None, 16, 16, 128)  0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 16, 16, 256)  0           average_pooling2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 16, 16, 128)  0           average_pooling2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 256)  1024        dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 128)  512         dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 384)  0           batch_normalization_39[0][0]     \n",
            "                                                                 batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 64)   221248      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 32)   102432      batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_30 (AveragePo (None, 8, 8, 64)     0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_31 (AveragePo (None, 8, 8, 32)     0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 8, 8, 64)     0           average_pooling2d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 8, 8, 32)     0           average_pooling2d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 8, 8, 64)     256         dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 8, 8, 32)     128         dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 8, 8, 96)     0           batch_normalization_41[0][0]     \n",
            "                                                                 batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 45)     38925       concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 16)     12816       batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_32 (AveragePo (None, 4, 4, 45)     0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_33 (AveragePo (None, 4, 4, 16)     0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 4, 4, 45)     0           average_pooling2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 4, 4, 16)     0           average_pooling2d_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 4, 4, 61)     0           dropout_42[0][0]                 \n",
            "                                                                 dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 976)          0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 976)          3904        flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 512)          500224      batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 512)          2048        dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 256)          131328      batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 10)           2570        dense_18[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,034,323\n",
            "Trainable params: 1,030,381\n",
            "Non-trainable params: 3,942\n",
            "__________________________________________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/150\n",
            "50000/50000 [==============================] - 17s 338us/sample - loss: 1.7435 - acc: 0.3857 - val_loss: 1.8613 - val_acc: 0.3570\n",
            "Epoch 2/150\n",
            "50000/50000 [==============================] - 15s 294us/sample - loss: 1.3956 - acc: 0.5052 - val_loss: 1.2593 - val_acc: 0.5590\n",
            "Epoch 3/150\n",
            "50000/50000 [==============================] - 15s 294us/sample - loss: 1.2480 - acc: 0.5601 - val_loss: 1.1475 - val_acc: 0.6039\n",
            "Epoch 4/150\n",
            "50000/50000 [==============================] - 15s 296us/sample - loss: 1.1248 - acc: 0.6075 - val_loss: 1.0246 - val_acc: 0.6491\n",
            "Epoch 5/150\n",
            "50000/50000 [==============================] - 15s 298us/sample - loss: 1.0306 - acc: 0.6399 - val_loss: 0.9888 - val_acc: 0.6615\n",
            "Epoch 6/150\n",
            "50000/50000 [==============================] - 15s 296us/sample - loss: 0.9668 - acc: 0.6629 - val_loss: 0.9310 - val_acc: 0.6821\n",
            "Epoch 7/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.9133 - acc: 0.6846 - val_loss: 0.8763 - val_acc: 0.6992\n",
            "Epoch 8/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.8638 - acc: 0.7013 - val_loss: 0.8261 - val_acc: 0.7186\n",
            "Epoch 9/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.8263 - acc: 0.7152 - val_loss: 0.8050 - val_acc: 0.7307\n",
            "Epoch 10/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.7882 - acc: 0.7299 - val_loss: 0.7746 - val_acc: 0.7371\n",
            "Epoch 11/150\n",
            "50000/50000 [==============================] - 15s 291us/sample - loss: 0.7609 - acc: 0.7392 - val_loss: 0.7411 - val_acc: 0.7483\n",
            "Epoch 12/150\n",
            "50000/50000 [==============================] - 15s 297us/sample - loss: 0.7242 - acc: 0.7515 - val_loss: 0.7172 - val_acc: 0.7575\n",
            "Epoch 13/150\n",
            "50000/50000 [==============================] - 15s 297us/sample - loss: 0.7021 - acc: 0.7631 - val_loss: 0.7046 - val_acc: 0.7677\n",
            "Epoch 14/150\n",
            "50000/50000 [==============================] - 15s 293us/sample - loss: 0.6753 - acc: 0.7694 - val_loss: 0.6894 - val_acc: 0.7703\n",
            "Epoch 15/150\n",
            "50000/50000 [==============================] - 15s 293us/sample - loss: 0.6487 - acc: 0.7797 - val_loss: 0.6798 - val_acc: 0.7717\n",
            "Epoch 16/150\n",
            "50000/50000 [==============================] - 15s 292us/sample - loss: 0.6309 - acc: 0.7856 - val_loss: 0.6668 - val_acc: 0.7793\n",
            "Epoch 17/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.6117 - acc: 0.7926 - val_loss: 0.6555 - val_acc: 0.7814\n",
            "Epoch 18/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.5870 - acc: 0.8020 - val_loss: 0.6546 - val_acc: 0.7854\n",
            "Epoch 19/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.5767 - acc: 0.8058 - val_loss: 0.6333 - val_acc: 0.7902\n",
            "Epoch 20/150\n",
            "50000/50000 [==============================] - 15s 296us/sample - loss: 0.5576 - acc: 0.8119 - val_loss: 0.6304 - val_acc: 0.7948\n",
            "Epoch 21/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.5387 - acc: 0.8191 - val_loss: 0.6317 - val_acc: 0.7955\n",
            "Epoch 22/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.5240 - acc: 0.8252 - val_loss: 0.6073 - val_acc: 0.8035\n",
            "Epoch 23/150\n",
            "50000/50000 [==============================] - 15s 294us/sample - loss: 0.5084 - acc: 0.8295 - val_loss: 0.6051 - val_acc: 0.8037\n",
            "Epoch 24/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.4912 - acc: 0.8356 - val_loss: 0.6058 - val_acc: 0.8019\n",
            "Epoch 25/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.4764 - acc: 0.8428 - val_loss: 0.6005 - val_acc: 0.8049\n",
            "Epoch 26/150\n",
            "50000/50000 [==============================] - 15s 296us/sample - loss: 0.4690 - acc: 0.8435 - val_loss: 0.5934 - val_acc: 0.8077\n",
            "Epoch 27/150\n",
            "50000/50000 [==============================] - 15s 295us/sample - loss: 0.4550 - acc: 0.8477 - val_loss: 0.5966 - val_acc: 0.8085\n",
            "Epoch 28/150\n",
            "50000/50000 [==============================] - 15s 296us/sample - loss: 0.4392 - acc: 0.8554 - val_loss: 0.5874 - val_acc: 0.8114\n",
            "Epoch 29/150\n",
            "50000/50000 [==============================] - 15s 293us/sample - loss: 0.4313 - acc: 0.8579 - val_loss: 0.5788 - val_acc: 0.8134\n",
            "Epoch 30/150\n",
            "50000/50000 [==============================] - 15s 294us/sample - loss: 0.4185 - acc: 0.8617 - val_loss: 0.5777 - val_acc: 0.8127\n",
            "Epoch 31/150\n",
            "50000/50000 [==============================] - 15s 294us/sample - loss: 0.4110 - acc: 0.8637 - val_loss: 0.5866 - val_acc: 0.8137\n",
            "Epoch 32/150\n",
            "50000/50000 [==============================] - 15s 294us/sample - loss: 0.3915 - acc: 0.8694 - val_loss: 0.5873 - val_acc: 0.8125\n",
            "Epoch 33/150\n",
            " 8520/50000 [====>.........................] - ETA: 11s - loss: 0.3687 - acc: 0.8744"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMzZYiHgrSAM"
      },
      "source": [
        "# **Architecture en Z v3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XaDfAZPqX8YD",
        "outputId": "917dcee4-7e3a-47fd-eea4-a378218695ce"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "#from keras.optimizers import Nadam,Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import keras.backend as K\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import (Activation, Conv2D,GlobalAveragePooling2D, Dense, Dropout, Flatten,AvgPool2D,MaxPooling2D,LeakyReLU,Input,Concatenate,Subtract)\n",
        "from tensorflow.python.keras.layers.noise import GaussianNoise\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam,Nadam\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import keras\n",
        "import math\n",
        "\n",
        "\n",
        "def preprocess_input(x, data_format=None):\n",
        "    \"\"\"Preprocesses a tensor encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: input Numpy tensor, 4D.\n",
        "        data_format: data format of the image tensor.\n",
        "    # Returns\n",
        "        Preprocessed tensor.\n",
        "    \"\"\"\n",
        "    if data_format is None:\n",
        "        data_format = K.image_data_format()\n",
        "    assert data_format in {'channels_last', 'channels_first'}\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        if x.ndim == 3:\n",
        "            # 'RGB'->'BGR'\n",
        "            x = x[::-1, ...]\n",
        "            # Zero-center by mean pixel\n",
        "            x[0, :, :] -= 103.939\n",
        "            x[1, :, :] -= 116.779\n",
        "            x[2, :, :] -= 123.68\n",
        "        else:\n",
        "            x = x[:, ::-1, ...]\n",
        "            x[:, 0, :, :] -= 103.939\n",
        "            x[:, 1, :, :] -= 116.779\n",
        "            x[:, 2, :, :] -= 123.68\n",
        "    else:\n",
        "        # 'RGB'->'BGR'\n",
        "        x = x[..., ::-1]\n",
        "        # Zero-center by mean pixel\n",
        "        x[..., 0] -= 103.939\n",
        "        x[..., 1] -= 116.779\n",
        "        x[..., 2] -= 123.68\n",
        "\n",
        "    x *= 0.017 # scale values\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\n",
        "trainX = trainX.astype('float32')\n",
        "testX = testX.astype('float32')\n",
        "\n",
        "#trainX = preprocess_input(trainX)\n",
        "#testX = preprocess_input(testX)\n",
        "nb_classes=10\n",
        "Y_train = np_utils.to_categorical(trainY, nb_classes)\n",
        "Y_test = np_utils.to_categorical(testY, nb_classes)\n",
        "\n",
        "batch_size = 100\n",
        "nb_epoch = 300\n",
        "weight_decay=1e-5\n",
        "data_format = 'channels_last'\n",
        "n_filters = 32         # number of convolutional filters to use\n",
        "kernel_size1 = (3, 3)  # shape of each convolutional filter\n",
        "kernel_size2 = (5, 5)\n",
        "kernel_size3 = (1, 1)\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "print('x_train shape:', trainX.shape)\n",
        "#print(train_images.shape[0], 'train samples')\n",
        "#print(test_images.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "#y_train = keras.utils.to_categorical(train_labels, num_classes)\n",
        "#y_test = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#train_images = np.reshape(train_images,(60000,28,28,1))\n",
        "#test_images = np.reshape(test_images,(10000,28,28,1))\n",
        "\n",
        "input_shape = trainX.shape[1:]\n",
        "# convert class vectors to binary class matrices\n",
        "#Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "#Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "    # construct Keras model\n",
        "    \n",
        "def InitialInputblockLevel(n, inputX,l1,l2):\n",
        "    outputD=[]\n",
        "    inputX=BatchNormalization()(inputX)\n",
        "    \n",
        "    \n",
        "    for i in range(n):\n",
        "      x1=Conv2D(l1, (i+1,i+1), padding='same',activation='relu',strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX)\n",
        "      x1=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x1)\n",
        "    \n",
        "      #x1=Dropout(0.25)(x1)\n",
        "      \n",
        "      outputD.append(x1)\n",
        "    \n",
        "    print(\"level1\",outputD)\n",
        "    return  outputD\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ConvBlock(inputX1,l1):\n",
        "    \n",
        "    \n",
        "    x1=Conv2D(l1, kernel_size2, padding='same',activation='relu', strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(inputX1)\n",
        "    \n",
        "    \n",
        "    x1=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x1)\n",
        "    \n",
        "    \n",
        "    x1=Dropout(0.25)(x1)\n",
        "   \n",
        "    \n",
        "    return x1\n",
        "\n",
        "def AIJ(inputX1,inputX2,l2):\n",
        "    \n",
        "    #inputX11=BatchNormalization()(inputX1)\n",
        "    #inputX21=BatchNormalization()(inputX2)\n",
        "\n",
        "    C=Concatenate(axis=3)([inputX1,inputX2])\n",
        "    x1=Conv2D(l2, kernel_size1, padding='same',activation='relu', strides=(1, 1), data_format=data_format,kernel_regularizer=keras.regularizers.l2(weight_decay))(C)\n",
        "    x1=AvgPool2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=data_format)(x1)\n",
        "    x1=Dropout(0.25)(x1)\n",
        "    \n",
        "    return x1\n",
        " \n",
        "      \n",
        "def blockCascade(n, inputsD,l1,l2):\n",
        "    outputD=[]\n",
        "    inputX11=BatchNormalization()(inputsD[0])\n",
        "    x1=ConvBlock(inputX11,l1)\n",
        "   \n",
        "\n",
        "    outputD.append(x1)\n",
        "    #outputD.append(x2)\n",
        "\n",
        "    for i in range(1,n):\n",
        "      inputX21=BatchNormalization()(inputsD[i])\n",
        "      inputX11=BatchNormalization()(inputsD[i-1])\n",
        "      x=AIJ(inputX11,inputX21,l2)\n",
        "      \n",
        "      outputD.append(x)\n",
        "      \n",
        "\n",
        "    return outputD\n",
        "\n",
        "def networkEncascade(n,m, InputX,l1,l2):\n",
        "    D=InitialInputblockLevel(m, InputX,128,128)\n",
        "    LevelDD=[]\n",
        "    LevelDD.append(D)\n",
        "    for i in range(1,n):\n",
        "      D=blockCascade(m, D,l1,l2)\n",
        "      LevelDD.append(D)\n",
        "    return  LevelDD[len(LevelDD)-1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "out=networkEncascade(2,2, inputs,64,32)\n",
        "x=Concatenate(axis=3)(out)\n",
        "x=BatchNormalization()(x)\n",
        "\n",
        "\n",
        "x=Flatten()(x)\n",
        "\n",
        "#x=BatchNormalization()(x)\n",
        "x=Dense(512,activation='relu')(x)\n",
        "Dropout(0.25)(x)\n",
        "\n",
        "x=BatchNormalization()(x)\n",
        "x=Dense(256,activation='relu')(x)\n",
        "Dropout(0.25)(x)\n",
        "x=Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "kmodel = Model(inputs, x)\n",
        "kmodel.summary()\n",
        "\n",
        "\n",
        "\n",
        "#model_optimizer = Adam(lr=1E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "lrr=1e-4\n",
        "\n",
        "model_optimizer=tensorflow.keras.optimizers.Nadam(lr=lrr, beta_1=0.9, beta_2=0.999, epsilon=1e-09)#, decay=lrr/epochs)\n",
        "#model_optimizer=RMSprop(1e-3)\n",
        "#model_optimizer = Adam(lr=lrr) # Using Adam instead of SGD to speed up training\n",
        "kmodel.compile(loss='categorical_crossentropy', optimizer=model_optimizer, metrics=[\"accuracy\"])\n",
        "print(\"Finished compiling\")\n",
        "print(\"Building model...\")\n",
        "\n",
        "\n",
        "\n",
        "#generator = ImageDataGenerator(rotation_range=15,\n",
        "#                               width_shift_range=5./32,\n",
        "#                               height_shift_range=5./32,\n",
        "#                               horizontal_flip=True)\n",
        "\n",
        "#generator.fit(trainX, seed=0)\n",
        "\n",
        "# Load model\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.007\n",
        "    drop = 0.75\n",
        "    epochs_drop = 10.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    print(\"learning rate:\",lrate, \"epoch :\",epoch)\n",
        "    return lrate\n",
        "\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "callbacks_list = [lrate]\n",
        "\n",
        "#model.fit_generator(generator.flow(trainX, Y_train, batch_size=batch_size),\n",
        "#                    steps_per_epoch=len(trainX) // batch_size, epochs=nb_epoch,\n",
        "#                    callbacks=callbacks,\n",
        "#                    validation_data=(testX, Y_test),\n",
        "#                    validation_steps=testX.shape[0] // batch_size, verbose=1)\n",
        "\n",
        "kmodel.fit(trainX, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
        "                    callbacks=callbacks_list, validation_data=(testX, Y_test), verbose=1)\n",
        "\n",
        "yPreds = model.predict(testX)\n",
        "yPred = np.argmax(yPreds, axis=1)\n",
        "yTrue = testY\n",
        "\n",
        "accuracy = metrics.accuracy_score(yTrue, yPred) * 100\n",
        "error = 100 - accuracy\n",
        "print(\"Accuracy : \", accuracy)\n",
        "print(\"Error : \", error)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "level1 [<tf.Tensor 'average_pooling2d_12/AvgPool:0' shape=(?, 16, 16, 128) dtype=float32>, <tf.Tensor 'average_pooling2d_13/AvgPool:0' shape=(?, 16, 16, 128) dtype=float32>]\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 3)    12          input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 128)  512         batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 128)  1664        batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 16, 16, 128)  0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 128)  512         average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 128)  512         average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 16, 16, 256)  0           batch_normalization_21[0][0]     \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   204864      batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 32)   73760       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 8, 8, 64)     0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 8, 8, 32)     0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 8, 8, 64)     0           average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 8, 8, 32)     0           average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 8, 8, 96)     0           dropout_18[0][0]                 \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 96)     384         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 6144)         0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 512)          3146240     flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 512)          2048        dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 256)          131328      batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 10)           2570        dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 3,564,918\n",
            "Trainable params: 3,562,928\n",
            "Non-trainable params: 1,990\n",
            "__________________________________________________________________________________________________\n",
            "Finished compiling\n",
            "Building model...\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "learning rate: 0.007 epoch : 0\n",
            "Epoch 1/300\n",
            "50000/50000 [==============================] - 13s 252us/sample - loss: 1.4220 - acc: 0.5157 - val_loss: 1.3271 - val_acc: 0.5479\n",
            "learning rate: 0.007 epoch : 1\n",
            "Epoch 2/300\n",
            "50000/50000 [==============================] - 11s 226us/sample - loss: 0.9753 - acc: 0.6600 - val_loss: 0.9939 - val_acc: 0.6627\n",
            "learning rate: 0.007 epoch : 2\n",
            "Epoch 3/300\n",
            "50000/50000 [==============================] - 11s 225us/sample - loss: 0.8276 - acc: 0.7169 - val_loss: 0.9362 - val_acc: 0.6909\n",
            "learning rate: 0.007 epoch : 3\n",
            "Epoch 4/300\n",
            "50000/50000 [==============================] - 11s 224us/sample - loss: 0.7153 - acc: 0.7611 - val_loss: 0.8841 - val_acc: 0.7183\n",
            "learning rate: 0.007 epoch : 4\n",
            "Epoch 5/300\n",
            "50000/50000 [==============================] - 11s 225us/sample - loss: 0.6325 - acc: 0.7900 - val_loss: 0.8855 - val_acc: 0.7216\n",
            "learning rate: 0.007 epoch : 5\n",
            "Epoch 6/300\n",
            "50000/50000 [==============================] - 11s 225us/sample - loss: 0.5779 - acc: 0.8127 - val_loss: 0.9656 - val_acc: 0.7020\n",
            "learning rate: 0.007 epoch : 6\n",
            "Epoch 7/300\n",
            "50000/50000 [==============================] - 11s 225us/sample - loss: 0.5232 - acc: 0.8339 - val_loss: 0.8997 - val_acc: 0.7353\n",
            "learning rate: 0.007 epoch : 7\n",
            "Epoch 8/300\n",
            "50000/50000 [==============================] - 11s 227us/sample - loss: 0.4611 - acc: 0.8558 - val_loss: 0.9845 - val_acc: 0.7154\n",
            "learning rate: 0.007 epoch : 8\n",
            "Epoch 9/300\n",
            "12900/50000 [======>.......................] - ETA: 7s - loss: 0.3754 - acc: 0.8866"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4bccca3ef312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m kmodel.fit(trainX, Y_train, batch_size=batch_size, epochs=nb_epoch,\n\u001b[0;32m--> 248\u001b[0;31m                     callbacks=callbacks_list, validation_data=(testX, Y_test), verbose=1)\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0myPreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}